{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read raw test and train data. As in submission file I need Ids, I will save IDs for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"data/test_data.csv\")\n",
    "\n",
    "IDS = test_data[\"ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read featuresets 1-6 which is generated from feature engineering notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reg\n",
    "tr1 = pd.read_csv(\"featuresets/tr1.csv\")\n",
    "ts1 = pd.read_csv(\"featuresets/ts1.csv\")\n",
    "\n",
    "# mean\n",
    "tr2 = pd.read_csv(\"featuresets/tr2.csv\")\n",
    "ts2 = pd.read_csv(\"featuresets/ts2.csv\")\n",
    "\n",
    "#knn\n",
    "tr3 = pd.read_csv(\"featuresets/tr3.csv\")\n",
    "ts3 = pd.read_csv(\"featuresets/ts3.csv\")\n",
    "\n",
    "#rfr\n",
    "tr4 = pd.read_csv(\"featuresets/tr4.csv\")\n",
    "ts4 = pd.read_csv(\"featuresets/ts4.csv\")\n",
    "\n",
    "#gbm\n",
    "tr5 = pd.read_csv(\"featuresets/tr5.csv\")\n",
    "ts5 = pd.read_csv(\"featuresets/ts5.csv\")\n",
    "\n",
    "#average\n",
    "tr6 = pd.read_csv(\"featuresets/tr6.csv\")\n",
    "ts6 = pd.read_csv(\"featuresets/ts6.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_train_test function is used to extract train data, labels and test data from featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unnamed: 0 is a column introduced by panda while reading files. It is just a row number so discarding it\n",
    "def get_train_test(tr,ts):\n",
    "    y = tr[\"Footfall\"]\n",
    "    x_train = tr.drop([\"Footfall\",\"Unnamed: 0\"],1)\n",
    "    x_test = ts.drop(\"Unnamed: 0\",1)\n",
    "    return(x_train,y,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train1 , y1 ,x_test1 = get_train_test(tr1,ts1)\n",
    "x_train2 , y2 ,x_test2 = get_train_test(tr2,ts2)\n",
    "x_train3 , y3 ,x_test3 = get_train_test(tr3,ts3)\n",
    "x_train4 , y4 ,x_test4 = get_train_test(tr4,ts4)\n",
    "x_train5 , y5 ,x_test5 = get_train_test(tr5,ts5)\n",
    "x_train6 , y6 ,x_test6 = get_train_test(tr6,ts6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write_csv is a function to save predictions which can be submitted on analytics vidhya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_csv(folder,fileName,df):\n",
    "    if os.path.isdir(folder) == False:\n",
    "        os.makedirs(folder)\n",
    "    sample_sub = df[['ID','Footfall']]\n",
    "    sample_sub.to_csv(folder+\"/sample_submissions_\"+fileName+\".csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict is the generalized function used to predict over test data and write predictions in comma separated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model,approach,name,t_data,IDs):\n",
    "    out_df = pd.DataFrame()\n",
    "    out_df['Footfall'] = model.predict(t_data)\n",
    "    out_df['ID'] = IDs\n",
    "    write_csv(\"results/\" + approach,name,out_df)\n",
    "    return(out_df['Footfall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achal/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor,BaggingRegressor,ExtraTreesRegressor,RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNetCV,RidgeCV,LassoCV,SGDRegressor,LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.cross_validation import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params1 = params_gbm = {'n_estimators': 500, 'max_depth': 4,\n",
    "          'learning_rate': 0.1, 'loss': 'ls'}\n",
    "params2 = params_gbm = {'n_estimators': 1000, 'max_depth': 5,\n",
    "          'learning_rate': 0.1, 'loss': 'ls'}\n",
    "params3 = params_gbm = {'n_estimators': 1500, 'max_depth': 4,\n",
    "          'learning_rate': 0.05, 'loss': 'ls'}\n",
    "params4 = params_gbm = {'n_estimators': 1500, 'max_depth': 5,\n",
    "          'learning_rate': 0.05, 'loss': 'ls'}\n",
    "params5 = params_gbm = {'n_estimators': 1000, 'max_depth': 4,\n",
    "          'learning_rate': 0.06, 'loss': 'ls'}\n",
    "params6 = params_gbm = {'n_estimators': 1000, 'max_depth': 5,\n",
    "          'learning_rate': 0.06, 'loss': 'ls'}\n",
    "params7 = params_gbm = {'n_estimators': 800, 'max_depth': 4,\n",
    "          'learning_rate': 0.11, 'loss': 'ls'}\n",
    "params8 = params_gbm = {'n_estimators': 800, 'max_depth': 5,\n",
    "          'learning_rate': 0.11, 'loss': 'ls'}\n",
    "params9 = params_gbm = {'n_estimators': 1200, 'max_depth': 4,\n",
    "          'learning_rate': 0.07, 'loss': 'ls'}\n",
    "params10 = params_gbm = {'n_estimators': 1200, 'max_depth': 5,\n",
    "          'learning_rate': 0.07, 'loss': 'ls'}\n",
    "\n",
    "gbm1 = GradientBoostingRegressor(**params1,verbose=1,subsample=0.8,random_state=10,max_features=\"sqrt\",min_samples_split=200)\n",
    "gbm2 = GradientBoostingRegressor(**params2,verbose=1,subsample=0.8,random_state=10,max_features=\"sqrt\",min_samples_split=200)\n",
    "gbm3 = GradientBoostingRegressor(**params3,verbose=1,subsample=0.8,random_state=10,max_features=\"sqrt\",min_samples_split=200)\n",
    "gbm4 = GradientBoostingRegressor(**params4,verbose=1,subsample=0.8,random_state=10,max_features=\"sqrt\",min_samples_split=200)\n",
    "gbm5 = GradientBoostingRegressor(**params5,verbose=1,subsample=0.8,random_state=10,max_features=\"sqrt\",min_samples_split=200)\n",
    "gbm6 = GradientBoostingRegressor(**params6,verbose=1,subsample=0.8,random_state=10,max_features=\"sqrt\",min_samples_split=200)\n",
    "gbm7 = GradientBoostingRegressor(**params7,verbose=1,subsample=0.8,random_state=10,max_features=\"sqrt\",min_samples_split=200)\n",
    "gbm8 = GradientBoostingRegressor(**params8,verbose=1,subsample=0.8,random_state=10,max_features=\"sqrt\",min_samples_split=200)\n",
    "gbm9 = GradientBoostingRegressor(**params9,verbose=1,subsample=0.8,random_state=10,max_features=\"sqrt\",min_samples_split=200)\n",
    "gbm10 = GradientBoostingRegressor(**params10,verbose=1,subsample=0.8,random_state=10,max_features=\"sqrt\",min_samples_split=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57998.9835        3716.5743           32.87s\n",
      "         2       54754.9588        3052.0278           30.71s\n",
      "         3       51642.0769        3159.2980           29.21s\n",
      "         4       49079.3707        2566.2222           29.23s\n",
      "         5       47121.2326        1913.1379           28.51s\n",
      "         6       45123.9728        1983.5710           27.99s\n",
      "         7       42897.3007        2260.1386           27.36s\n",
      "         8       40840.2013        2015.3250           27.09s\n",
      "         9       38838.9774        2101.5728           27.33s\n",
      "        10       37083.2431        1770.7231           26.94s\n",
      "        20       25959.3796         874.8431           25.44s\n",
      "        30       21137.2872         252.9421           24.14s\n",
      "        40       18620.5496         128.9101           23.47s\n",
      "        50       17117.4733         104.2233           22.78s\n",
      "        60       15767.7580          40.7403           22.18s\n",
      "        70       14578.1103          84.8625           21.73s\n",
      "        80       13790.1247         198.4835           21.24s\n",
      "        90       13042.6179          61.5376           20.75s\n",
      "       100       12363.7934          84.2333           20.17s\n",
      "       200        9087.6601          28.6696           15.57s\n",
      "       300        7761.8963           7.9210           10.54s\n",
      "       400        7020.6492           5.2323            5.25s\n",
      "       500        6548.8579           2.6547            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57275.1518        4414.0488            1.27m\n",
      "         2       53094.8308        3976.6418            1.30m\n",
      "         3       49634.8585        3517.0756            1.25m\n",
      "         4       46675.9836        3001.8210            1.21m\n",
      "         5       44264.7456        2322.7808            1.19m\n",
      "         6       41690.0815        2588.7951            1.18m\n",
      "         7       39234.9702        2495.6496            1.16m\n",
      "         8       36186.4242        3014.5261            1.15m\n",
      "         9       34419.3245        1866.8797            1.14m\n",
      "        10       32132.2791        2353.3961            1.13m\n",
      "        20       22959.7894         527.1019            1.10m\n",
      "        30       18110.9829         210.3758            1.05m\n",
      "        40       15571.7109          93.0682            1.03m\n",
      "        50       13756.7090         140.9660            1.02m\n",
      "        60       12830.3997          90.4558            1.01m\n",
      "        70       11974.2053          51.5525           59.55s\n",
      "        80       11273.4079          55.8245           58.58s\n",
      "        90       10448.9407          34.1919           57.99s\n",
      "       100       10009.7818          54.6618           57.26s\n",
      "       200        7492.8976          27.8711           50.66s\n",
      "       300        6407.6415           8.5171           43.94s\n",
      "       400        5834.6575           0.9787           37.36s\n",
      "       500        5417.8187           1.9548           30.80s\n",
      "       600        5088.7846           2.0253           24.40s\n",
      "       700        4857.1062           0.2610           18.18s\n",
      "       800        4602.9321           0.0019           12.05s\n",
      "       900        4412.4612          -0.1638            6.01s\n",
      "      1000        4237.5107           0.1964            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59850.9423        1880.1103            1.43m\n",
      "         2       57946.9647        1738.6899            1.34m\n",
      "         3       56141.6433        1866.3202            1.31m\n",
      "         4       54115.7565        2035.5814            1.26m\n",
      "         5       52726.7024        1343.9769            1.24m\n",
      "         6       51337.2200        1415.8777            1.24m\n",
      "         7       49826.9004        1537.1504            1.23m\n",
      "         8       48604.6488        1157.3849            1.23m\n",
      "         9       47097.9014        1603.8694            1.22m\n",
      "        10       45591.2009        1574.4202            1.21m\n",
      "        20       36118.2934         919.9122            1.19m\n",
      "        30       29253.6582         388.7001            1.17m\n",
      "        40       25435.9091         200.4094            1.16m\n",
      "        50       22993.3298         174.1676            1.15m\n",
      "        60       21327.8758         127.4866            1.13m\n",
      "        70       19837.6873          79.1528            1.12m\n",
      "        80       18672.3879         158.1844            1.11m\n",
      "        90       17781.8227          53.9643            1.10m\n",
      "       100       17050.5516         144.8068            1.09m\n",
      "       200       12220.6494          41.6162            1.01m\n",
      "       300        9920.2874          18.0810           55.71s\n",
      "       400        8767.6376          24.8047           51.01s\n",
      "       500        8058.9517          14.4822           46.30s\n",
      "       600        7561.5071           4.3873           41.61s\n",
      "       700        7223.3805           1.1575           36.84s\n",
      "       800        6908.8987           0.4976           32.27s\n",
      "       900        6641.6342           0.2859           28.43s\n",
      "      1000        6430.0753           1.5139           23.65s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59615.7955        2103.8802            2.24m\n",
      "         2       57473.5127        1984.0495            2.07m\n",
      "         3       55452.9848        2100.9601            1.98m\n",
      "         4       53063.7877        2381.8613            1.89m\n",
      "         5       51544.4773        1482.5809            1.84m\n",
      "         6       49690.8964        1896.9634            1.81m\n",
      "         7       47609.5388        2096.0872            1.80m\n",
      "         8       46200.6748        1349.9697            1.79m\n",
      "         9       44570.8708        1720.0217            1.77m\n",
      "        10       43298.0718        1291.5735            1.75m\n",
      "        20       32461.5023         950.8439            1.72m\n",
      "        30       26270.8118         420.3216            1.84m\n",
      "        40       22661.7713         250.1398            1.78m\n",
      "        50       20326.7010         225.5383            1.80m\n",
      "        60       18613.5345          87.4532            1.75m\n",
      "        70       16698.8106          87.7944            1.72m\n",
      "        80       15536.8547         199.5579            1.74m\n",
      "        90       14649.1753          66.2670            1.72m\n",
      "       100       13931.4092          57.1585            1.70m\n",
      "       200        9292.7566          22.4478            1.65m\n",
      "       300        7321.4508          10.6100            1.50m\n",
      "       400        6370.3744           6.2644            1.35m\n",
      "       500        5825.5927           4.6965            1.20m\n",
      "       600        5381.2562           1.7005            1.06m\n",
      "       700        5029.4432           1.7618           56.01s\n",
      "       800        4748.8952           2.5430           48.41s\n",
      "       900        4516.9303           0.5119           41.10s\n",
      "      1000        4345.0339           0.1348           33.97s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59317.6672        2437.2684           57.11s\n",
      "         2       55472.6595        3706.7161           51.89s\n",
      "         3       53592.9595        1955.9963           50.71s\n",
      "         4       51701.7858        1886.2592           50.50s\n",
      "         5       49765.4576        1851.6527           50.95s\n",
      "         6       48412.7923        1368.8557           50.95s\n",
      "         7       47108.9039        1357.3405           51.08s\n",
      "         8       45682.6748        1343.2311           50.82s\n",
      "         9       44337.2633        1433.7632           50.60s\n",
      "        10       43264.0075        1138.8625           50.43s\n",
      "        20       32316.5410         543.4399           48.88s\n",
      "        30       26525.8706         303.3782           49.60s\n",
      "        40       23438.2028         440.2809           48.97s\n",
      "        50       21260.2463         156.6185           48.11s\n",
      "        60       19729.7274          99.0090           47.16s\n",
      "        70       18427.8646          68.0938           46.48s\n",
      "        80       17480.5027          76.6137           45.63s\n",
      "        90       16742.4505          52.0977           45.13s\n",
      "       100       15959.3179          55.2127           44.45s\n",
      "       200       11333.9266          37.3058           40.52s\n",
      "       300        9333.0850           4.5223           35.13s\n",
      "       400        8301.5568           1.2414           30.06s\n",
      "       500        7634.7135           4.9989           24.81s\n",
      "       600        7139.8817           0.9738           19.70s\n",
      "       700        6833.9942           2.6298           14.74s\n",
      "       800        6488.6821           0.9369            9.81s\n",
      "       900        6225.3782           0.6841            4.88s\n",
      "      1000        6042.8579           0.8034            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59192.8972        2517.5770            1.36m\n",
      "         2       56632.1025        2369.3799            1.28m\n",
      "         3       54202.2575        2514.7331            1.27m\n",
      "         4       51829.8441        2373.2659            1.25m\n",
      "         5       50063.9706        1696.4962            1.23m\n",
      "         6       47909.1599        2193.8741            1.21m\n",
      "         7       46072.7207        1844.1047            1.20m\n",
      "         8       44413.0857        1613.9423            1.20m\n",
      "         9       42762.8081        1745.1764            1.20m\n",
      "        10       41000.1834        1785.4610            1.19m\n",
      "        20       30367.9859         580.9464            1.15m\n",
      "        30       23868.5777         391.1746            1.13m\n",
      "        40       20560.0622         208.6249            1.10m\n",
      "        50       18217.7628         185.6440            1.09m\n",
      "        60       16424.7339         133.8492            1.07m\n",
      "        70       15156.6373          83.3488            1.06m\n",
      "        80       14081.4345         167.2132            1.05m\n",
      "        90       13230.7264          73.2959            1.03m\n",
      "       100       12477.2172          65.4452            1.02m\n",
      "       200        8694.1963          39.0248           53.26s\n",
      "       300        7157.9360           8.8749           46.01s\n",
      "       400        6409.7271           5.7874           38.81s\n",
      "       500        5902.8625           3.4256           32.12s\n",
      "       600        5503.2550           1.2881           25.59s\n",
      "       700        5226.7800           2.2103           19.08s\n",
      "       800        4971.2580           0.2466           12.64s\n",
      "       900        4777.2753           0.5167            6.28s\n",
      "      1000        4621.2696           0.4654            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57976.9884        3765.4981           45.20s\n",
      "         2       53963.7171        3842.6290           41.00s\n",
      "         3       50237.0708        3773.7059           39.93s\n",
      "         4       46704.6173        3533.0217           38.35s\n",
      "         5       44319.0425        2293.4879           38.15s\n",
      "         6       42327.2123        2012.1200           38.44s\n",
      "         7       39928.9052        2449.3160           38.35s\n",
      "         8       38162.2378        1766.0013           38.06s\n",
      "         9       36646.2538        1576.9870           37.82s\n",
      "        10       35235.7209        1470.9509           37.53s\n",
      "        20       25487.7788         963.8090           36.96s\n",
      "        30       20427.4703         156.6473           35.53s\n",
      "        40       17948.1089          93.6238           34.89s\n",
      "        50       16238.6999         177.3508           36.83s\n",
      "        60       15011.8656         121.9822           37.87s\n",
      "        70       14072.0319          37.4978           37.09s\n",
      "        80       13454.5321          62.7336           37.79s\n",
      "        90       12716.1097          56.5411           38.36s\n",
      "       100       12242.3136          54.4718           38.72s\n",
      "       200        9181.6853          33.1005           34.01s\n",
      "       300        7906.0082           3.2840           27.30s\n",
      "       400        7244.5112           2.5807           22.33s\n",
      "       500        6815.3845           2.4345           16.29s\n",
      "       600        6451.6993           1.3942           10.57s\n",
      "       700        6204.8224           0.1670            5.28s\n",
      "       800        5960.8251           0.1741            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57181.5470        4509.1659            1.10m\n",
      "         2       52900.7183        4095.9822            1.04m\n",
      "         3       49084.5118        3884.3186            1.04m\n",
      "         4       45072.9706        4088.5514            1.03m\n",
      "         5       42350.0828        2642.5483            1.03m\n",
      "         6       39521.1074        2847.2591            1.03m\n",
      "         7       37091.8219        2447.1387            1.03m\n",
      "         8       34144.8901        2887.0373            1.02m\n",
      "         9       32200.0149        2008.8351            1.01m\n",
      "        10       29451.9831        2832.5521            1.00m\n",
      "        20       20151.7817         666.2826           57.71s\n",
      "        30       15896.8149          90.9979           54.48s\n",
      "        40       13811.1637         112.3702           52.87s\n",
      "        50       12522.8416         158.9917           51.15s\n",
      "        60       11473.6935          61.6542           49.96s\n",
      "        70       10815.5332          33.0290           49.32s\n",
      "        80       10187.9748          51.9185           48.78s\n",
      "        90        9571.2763          26.6893           48.53s\n",
      "       100        8973.2752          45.9758           48.15s\n",
      "       200        6777.4519          21.8373           41.01s\n",
      "       300        5907.1649           5.3754           33.48s\n",
      "       400        5303.5390           2.8679           26.83s\n",
      "       500        4902.4994           2.7211           20.01s\n",
      "       600        4569.9075           1.9038           13.20s\n",
      "       700        4294.2038           2.1560            6.55s\n",
      "       800        4077.7892           0.4187            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59149.3586        2570.8340            1.23m\n",
      "         2       56633.8726        2350.1247            1.13m\n",
      "         3       54217.0813        2453.7421            1.10m\n",
      "         4       51609.8648        2637.4038            1.05m\n",
      "         5       49896.6357        1639.7837            1.07m\n",
      "         6       48234.9664        1695.1731            1.07m\n",
      "         7       46403.1315        1844.7938            1.08m\n",
      "         8       45086.2257        1252.0277            1.07m\n",
      "         9       43295.9062        1905.5405            1.05m\n",
      "        10       41558.5195        1770.1512            1.05m\n",
      "        20       30697.9592         916.6980            1.02m\n",
      "        30       24672.4654         309.0956           59.43s\n",
      "        40       21884.2515         138.9432           59.32s\n",
      "        50       19834.9674         167.6729           58.43s\n",
      "        60       18237.7011          78.2165           58.15s\n",
      "        70       16964.8861          69.4736           57.78s\n",
      "        80       16046.3210         102.7227           57.57s\n",
      "        90       15290.3739          42.1898           57.21s\n",
      "       100       14397.2223         139.2989           57.27s\n",
      "       200       10267.0743          20.0707           52.17s\n",
      "       300        8448.8786          13.3384           46.27s\n",
      "       400        7482.7520           4.3533           40.60s\n",
      "       500        6919.6164           6.8882           35.32s\n",
      "       600        6436.5943           2.6686           30.36s\n",
      "       700        6085.5865           2.0213           25.48s\n",
      "       800        5770.9472           1.2353           20.31s\n",
      "       900        5570.7842           0.8962           15.19s\n",
      "      1000        5373.2633           0.6544           10.15s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58378.9901        3372.7764            1.54m\n",
      "         2       55238.7786        2961.2720            1.49m\n",
      "         3       52879.2191        2443.5853            1.44m\n",
      "         4       50054.1318        2839.9083            1.43m\n",
      "         5       47476.8411        2460.6917            1.42m\n",
      "         6       45830.0730        1706.6545            1.41m\n",
      "         7       44198.6211        1626.8629            1.40m\n",
      "         8       42294.4393        1870.9611            1.39m\n",
      "         9       40562.7142        1825.9254            1.37m\n",
      "        10       39280.9379        1293.1108            1.38m\n",
      "        20       26894.2274         682.2053            1.38m\n",
      "        30       21006.6253         263.9438            1.41m\n",
      "        40       18314.8911         332.5875            1.43m\n",
      "        50       16194.8944         189.1658            1.40m\n",
      "        60       15067.5100          91.0910            1.37m\n",
      "        70       14048.1753          63.4028            1.37m\n",
      "        80       13204.2651          90.1061            1.34m\n",
      "        90       12436.8818          61.8954            1.32m\n",
      "       100       11680.8360          50.9703            1.32m\n",
      "       200        8206.4887          16.6236            1.23m\n",
      "       300        6841.2888           5.1053            1.10m\n",
      "       400        6059.7809           3.2505           58.39s\n",
      "       500        5617.7833           3.1640           50.91s\n",
      "       600        5238.9721           1.4416           43.37s\n",
      "       700        4997.4419           0.8342           35.87s\n",
      "       800        4738.3157           1.6549           28.75s\n",
      "       900        4530.1367           0.4196           21.44s\n",
      "      1000        4387.7077           0.1968           14.14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.07, loss='ls', max_depth=5,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1200, presort='auto', random_state=10,\n",
       "             subsample=0.8, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm1.fit(x_train1,y1)\n",
    "gbm2.fit(x_train2,y2)\n",
    "gbm3.fit(x_train3,y3)\n",
    "gbm4.fit(x_train4,y4)\n",
    "gbm5.fit(x_train6,y6)\n",
    "gbm6.fit(x_train1,y1)\n",
    "gbm7.fit(x_train2,y2)\n",
    "gbm8.fit(x_train3,y3)\n",
    "gbm9.fit(x_train4,y4)\n",
    "gbm10.fit(x_train6,y6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_out1 = predict(gbm1,\"approach1\",\"gbr1\",x_test1,IDS)\n",
    "gbm_out2 = predict(gbm2,\"approach1\",\"gbr2\",x_test2,IDS)\n",
    "gbm_out3 = predict(gbm3,\"approach1\",\"gbr3\",x_test3,IDS)\n",
    "gbm_out4 = predict(gbm4,\"approach1\",\"gbr4\",x_test4,IDS)\n",
    "gbm_out5 = predict(gbm5,\"approach1\",\"gbr5\",x_test6,IDS)\n",
    "gbm_out6 = predict(gbm6,\"approach1\",\"gbr6\",x_test1,IDS)\n",
    "gbm_out7 = predict(gbm7,\"approach1\",\"gbr7\",x_test2,IDS)\n",
    "gbm_out8 = predict(gbm8,\"approach1\",\"gbr8\",x_test3,IDS)\n",
    "gbm_out9 = predict(gbm9,\"approach1\",\"gbr9\",x_test4,IDS)\n",
    "gbm_out10 = predict(gbm10,\"approach1\",\"gbr10\",x_test6,IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After submitting all the models on analytics vidhya, I found out that GBR 4,5,8,9 are working good with the given parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to bag them by taking average of these 4 models and lets see if score improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()\n",
    "out_df['Footfall'] = (gbm_out4 + gbm_out5 + gbm_out8 + gbm_out9)/4\n",
    "out_df['ID'] = IDS\n",
    "write_csv(\"results/approach1\",\"gbm_combined\",out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It improved public score significally LB ~ 128. so lets try to predict over all the featuresets by using best gbr model. (Model - 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.07, loss='ls', max_depth=4,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1200, presort='auto', random_state=10,\n",
       "             subsample=0.8, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: ** I don't want to leak the data, so I am not including featureset in which missing values are predicted using gradient boosting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59085.9830        2642.9978            1.30m\n",
      "         2       56665.6601        2234.9656            1.21m\n",
      "         3       54312.4111        2414.1881            1.16m\n",
      "         4       52230.1275        2066.7512            1.21m\n",
      "         5       50619.5347        1572.6736            1.23m\n",
      "         6       48925.3212        1694.8392            1.21m\n",
      "         7       47038.7926        1921.8720            1.18m\n",
      "         8       45586.3630        1399.0576            1.18m\n",
      "         9       43768.8297        1915.7022            1.15m\n",
      "        10       42166.6958        1642.6997            1.13m\n",
      "        20       30995.7361         937.6667            1.06m\n",
      "        30       25129.0960         301.8151            1.03m\n",
      "        40       21637.9503         161.9251            1.01m\n",
      "        50       19528.7664         164.4590            1.09m\n",
      "        60       17785.3394          59.6953            1.13m\n",
      "        70       16579.0938          61.4167            1.09m\n",
      "        80       15557.1756         150.1284            1.07m\n",
      "        90       14753.0678          47.5495            1.04m\n",
      "       100       13997.0236         149.6773            1.02m\n",
      "       200       10167.3837          45.9696           58.37s\n",
      "       300        8648.4071          11.0251           51.65s\n",
      "       400        7771.6444          23.7479           44.89s\n",
      "       500        7289.7599           1.4050           39.23s\n",
      "       600        6909.1187           1.4218           33.35s\n",
      "       700        6530.6531           0.7824           27.52s\n",
      "       800        6251.8841           0.0552           22.11s\n",
      "       900        6040.5653          -0.0483           16.28s\n",
      "      1000        5850.5915           5.1529           10.69s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59301.9988        2447.1898            1.16m\n",
      "         2       56562.7523        2571.1618            1.05m\n",
      "         3       53964.6752        2658.2823            1.04m\n",
      "         4       51872.5993        2099.7865            1.04m\n",
      "         5       49996.8555        1805.9994            1.03m\n",
      "         6       48346.1756        1675.0439            1.01m\n",
      "         7       46502.5638        1889.0637           59.99s\n",
      "         8       44971.5832        1488.5696           59.23s\n",
      "         9       43841.8487        1204.2785           59.36s\n",
      "        10       42484.5470        1410.6963           58.89s\n",
      "        20       33022.9323         536.2971           57.40s\n",
      "        30       26387.4257         315.8507           55.75s\n",
      "        40       23497.2049         135.7341           55.34s\n",
      "        50       21391.7742         176.0151           54.84s\n",
      "        60       19853.5280         138.5433           54.03s\n",
      "        70       18362.4916          71.7934           53.36s\n",
      "        80       17235.1371         152.8249           52.71s\n",
      "        90       16150.9693          96.8262           52.45s\n",
      "       100       15460.6833         107.2202           51.92s\n",
      "       200       10958.1242          49.4042           46.92s\n",
      "       300        9085.5249           6.9357           42.63s\n",
      "       400        8188.8153           8.0083           38.59s\n",
      "       500        7666.8531          11.3592           33.42s\n",
      "       600        7234.1152           3.9345           28.76s\n",
      "       700        6930.2678           0.8829           23.89s\n",
      "       800        6621.4854           3.1123           19.19s\n",
      "       900        6401.2042          -0.0570           14.32s\n",
      "      1000        6241.6708           1.3302            9.58s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59114.3794        2604.9421            1.16m\n",
      "         2       56585.2655        2364.3564            1.06m\n",
      "         3       54173.6663        2464.7594            1.03m\n",
      "         4       51583.0151        2643.8918           59.93s\n",
      "         5       49832.6550        1673.4828           59.81s\n",
      "         6       48123.3762        1721.1171           59.70s\n",
      "         7       46314.3081        1834.8632           58.87s\n",
      "         8       44521.4447        1741.2002           58.58s\n",
      "         9       42767.2794        1850.2588           58.32s\n",
      "        10       41094.5587        1715.3190           58.07s\n",
      "        20       30479.9720         893.9609           57.32s\n",
      "        30       24568.0826         305.2573           55.64s\n",
      "        40       21740.8356         137.5474           54.75s\n",
      "        50       19769.6842         121.9455           54.08s\n",
      "        60       18183.8545          74.1045           53.27s\n",
      "        70       17061.8346          64.6867           52.89s\n",
      "        80       15947.4642         107.2345           52.15s\n",
      "        90       15272.7156          48.7239           51.73s\n",
      "       100       14559.9318          83.2048           51.23s\n",
      "       200       10640.2568          46.1477           48.59s\n",
      "       300        8841.7210          18.2186           49.20s\n",
      "       400        7915.7391           1.7789           43.77s\n",
      "       500        7407.5221           3.3969           38.02s\n",
      "       600        6943.8059           1.9041           32.84s\n",
      "       700        6607.0176           1.7661           27.28s\n",
      "       800        6297.6336           0.5781           21.81s\n",
      "       900        6050.0423           0.8849           16.61s\n",
      "      1000        5858.6012           0.8436           11.01s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59149.3586        2570.8340            1.19m\n",
      "         2       56633.8726        2350.1247            1.13m\n",
      "         3       54217.0813        2453.7421            1.12m\n",
      "         4       51609.8648        2637.4038            1.10m\n",
      "         5       49896.6357        1639.7837            1.08m\n",
      "         6       48234.9664        1695.1731            1.07m\n",
      "         7       46403.1315        1844.7938            1.05m\n",
      "         8       45086.2257        1252.0277            1.04m\n",
      "         9       43295.9062        1905.5405            1.04m\n",
      "        10       41558.5195        1770.1512            1.03m\n",
      "        20       30697.9592         916.6980           59.75s\n",
      "        30       24672.4654         309.0956           58.07s\n",
      "        40       21884.2515         138.9432           57.59s\n",
      "        50       19834.9674         167.6729           56.57s\n",
      "        60       18237.7011          78.2165           55.72s\n",
      "        70       16964.8861          69.4736           55.16s\n",
      "        80       16046.3210         102.7227           54.76s\n",
      "        90       15290.3739          42.1898           55.91s\n",
      "       100       14397.2223         139.2989           55.44s\n",
      "       200       10267.0743          20.0707           56.64s\n",
      "       300        8448.8786          13.3384           48.61s\n",
      "       400        7482.7520           4.3533           44.34s\n",
      "       500        6919.6164           6.8882           39.06s\n",
      "       600        6436.5943           2.6686           33.60s\n",
      "       700        6085.5865           2.0213           28.05s\n",
      "       800        5770.9472           1.2353           22.49s\n",
      "       900        5570.7842           0.8962           16.88s\n",
      "      1000        5373.2633           0.6544           11.23s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58925.1527        2828.6937            1.67m\n",
      "         2       54533.4200        4258.1001            1.48m\n",
      "         3       52403.3244        2203.7169            1.44m\n",
      "         4       50312.5889        2097.4362            1.42m\n",
      "         5       48172.7348        2040.6237            1.38m\n",
      "         6       46706.3056        1483.2309            1.37m\n",
      "         7       45300.9673        1462.5736            1.39m\n",
      "         8       43790.3422        1425.2578            1.38m\n",
      "         9       42354.2464        1523.1980            1.36m\n",
      "        10       41224.0007        1193.1048            1.34m\n",
      "        20       29629.6708         503.7617            1.19m\n",
      "        30       24416.9809         270.4445            1.15m\n",
      "        40       21645.0000         398.8264            1.18m\n",
      "        50       19300.2269         279.8609            1.16m\n",
      "        60       18034.7495         173.8065            1.12m\n",
      "        70       16900.4269          68.8668            1.08m\n",
      "        80       16070.4966          95.8804            1.05m\n",
      "        90       15453.3448          47.0949            1.02m\n",
      "       100       14820.3071          48.6658            1.00m\n",
      "       200       10742.7247          26.0514           52.71s\n",
      "       300        8869.4576          10.5113           46.51s\n",
      "       400        7990.6481           6.0387           40.79s\n",
      "       500        7439.3463           5.6358           35.49s\n",
      "       600        6950.5941           0.5200           30.24s\n",
      "       700        6684.0559           2.5538           25.25s\n",
      "       800        6381.5873           0.1946           20.15s\n",
      "       900        6134.4907           0.8886           15.03s\n",
      "      1000        5942.3664           0.6192           10.01s\n"
     ]
    }
   ],
   "source": [
    "gbm9.fit(x_train1,y1)\n",
    "gbm_out11 = predict(gbm9,\"approach1\",\"gbr91\",x_test1,IDS)\n",
    "\n",
    "gbm9.fit(x_train2,y2)\n",
    "gbm_out12 = predict(gbm9,\"approach1\",\"gbr92\",x_test2,IDS)\n",
    "\n",
    "gbm9.fit(x_train3,y3)\n",
    "gbm_out13 = predict(gbm9,\"approach1\",\"gbr93\",x_test3,IDS)\n",
    "\n",
    "gbm9.fit(x_train4,y4)\n",
    "gbm_out14 = predict(gbm9,\"approach1\",\"gbr94\",x_test4,IDS)\n",
    "\n",
    "gbm9.fit(x_train6,y6)\n",
    "gbm_out15 = predict(gbm9,\"approach1\",\"gbr95\",x_test6,IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()\n",
    "out_df['Footfall'] = (gbm_out11 + gbm_out12 + gbm_out13 + gbm_out14 + gbm_out15 )/5\n",
    "out_df['ID'] = IDS\n",
    "write_csv(\"results/approach1\",\"gbm9_combined\",out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gave LB score around 129. (Best score till now ~ 128). So lets do something better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to analyze feature imporance calculated by gradient boosing regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f912c152128>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAGeCAYAAACQBaYTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJDo53Cvf4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f912c190c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "feat_imp = pd.Series(gbm9.feature_importances_, x_train1.columns).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have only focused on gradient boosting regressor till now and spent enough time to tune GBR. Lets try different machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random forest regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build random forest regressor using top parameters. I used grid search to tune these parameters. Here also, I don't want any data leakage so I will not train rfr on featureset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr1 = RandomForestRegressor(max_features=\"sqrt\",max_depth=4,random_state=10,n_estimators=200)\n",
    "rfr2 = RandomForestRegressor(max_features=\"sqrt\",max_depth=5,random_state=10,n_estimators=200)\n",
    "rfr3 = RandomForestRegressor(max_features=\"sqrt\",max_depth=4,random_state=10,n_estimators=200)\n",
    "rfr4 = RandomForestRegressor(max_features=\"sqrt\",max_depth=5,random_state=10,n_estimators=200)\n",
    "rfr5 = RandomForestRegressor(max_features=\"sqrt\",max_depth=4,random_state=10,n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=4,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=200, n_jobs=1, oob_score=False, random_state=10,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr1.fit(x_train1,y1)\n",
    "rfr2.fit(x_train2,y2)\n",
    "rfr3.fit(x_train3,y3)\n",
    "rfr4.fit(x_train5,y5)\n",
    "rfr5.fit(x_train6,y6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfr_out1 = predict(rfr1,\"approach2\",\"rfr1\",x_test1,IDS)\n",
    "rfr_out2 = predict(rfr2,\"approach2\",\"rfr2\",x_test2,IDS)\n",
    "rfr_out3 = predict(rfr3,\"approach2\",\"rfr3\",x_test3,IDS)\n",
    "rfr_out4 = predict(rfr4,\"approach2\",\"rfr4\",x_test5,IDS)\n",
    "rfr_out5 = predict(rfr5,\"approach2\",\"rfr5\",x_test6,IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest regressor performed worse than gradient boosting regressor. But some of the rfr models performed close enough to gradient boosting regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before considering these models, lets see what happens if I take average of all the stage 0 models I built till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()\n",
    "out_df['Footfall'] = (gbm_out1 + gbm_out2 + gbm_out3 + gbm_out4 + gbm_out5 + \n",
    "                      gbm_out6 + gbm_out7 + gbm_out8 + gbm_out9 + gbm_out10+ \n",
    "                      rfr_out1 + rfr_out2 + rfr_out3 + rfr_out4 + rfr_out5)/15\n",
    "out_df['ID'] = IDS\n",
    "write_csv(\"results/approach2\",\"gbm_rfr_combined\",out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB ~ 142. (Best LB score till now ~ 128, so it did not work for me) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()\n",
    "out_df['Footfall'] = (gbm_out4 + gbm_out5 + gbm_out8 + gbm_out9 + rfr_out3 + rfr_out5)/6\n",
    "out_df['ID'] = IDS\n",
    "write_csv(\"results/approach2\",\"gbm_rfr_best_combined\",out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB ~ 132. (Best LB score till now ~ 128, so it is still worse than best score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extra trees regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etr1 = ExtraTreesRegressor(max_features=\"sqrt\",max_depth=4,random_state=10,n_estimators=300)\n",
    "etr2 = ExtraTreesRegressor(max_features=\"sqrt\",max_depth=5,random_state=10,n_estimators=400)\n",
    "etr3 = ExtraTreesRegressor(max_features=\"sqrt\",max_depth=4,random_state=10,n_estimators=300)\n",
    "etr4 = ExtraTreesRegressor(max_features=\"sqrt\",max_depth=5,random_state=10,n_estimators=200)\n",
    "etr5 = ExtraTreesRegressor(max_features=\"sqrt\",max_depth=4,random_state=10,n_estimators=300)\n",
    "etr6 = ExtraTreesRegressor(max_features=\"sqrt\",max_depth=4,random_state=10,n_estimators=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=4,\n",
       "          max_features='sqrt', max_leaf_nodes=None,\n",
       "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "          n_estimators=400, n_jobs=1, oob_score=False, random_state=10,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etr1.fit(x_train1,y1)\n",
    "etr2.fit(x_train2,y2)\n",
    "etr3.fit(x_train3,y3)\n",
    "etr4.fit(x_train4,y4)\n",
    "etr5.fit(x_train5,y5)\n",
    "etr6.fit(x_train6,y6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etr_out1 = predict(etr1,\"approach3\",\"etr1\",x_test1,IDS)\n",
    "etr_out2 = predict(etr2,\"approach3\",\"etr2\",x_test2,IDS)\n",
    "etr_out3 = predict(etr3,\"approach3\",\"etr3\",x_test3,IDS)\n",
    "etr_out4 = predict(etr4,\"approach3\",\"etr4\",x_test4,IDS)\n",
    "etr_out5 = predict(etr5,\"approach3\",\"etr5\",x_test5,IDS)\n",
    "etr_out6 = predict(etr6,\"approach3\",\"etr6\",x_test6,IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()\n",
    "out_df['Footfall'] = (gbm_out1 + gbm_out2 + gbm_out3 + gbm_out4 + gbm_out5 + \n",
    "                      gbm_out6 + gbm_out7 + gbm_out8 + gbm_out9 + gbm_out10+ \n",
    "                      rfr_out1 + rfr_out2 + rfr_out3 + rfr_out4 + rfr_out5 +\n",
    "                     etr_out1 + etr_out2 + etr_out3 + etr_out4 +etr_out5 + etr_out6)/31\n",
    "out_df['ID'] = IDS\n",
    "write_csv(\"results/approach3\",\"gbm_rfr_etr_combined\",out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()\n",
    "out_df['Footfall'] = (gbm_out11 + gbm_out12 + gbm_out13 + gbm_out14 + gbm_out15 + \n",
    "                      rfr_out3 + rfr_out5 + etr_out3 + etr_out5)/7\n",
    "out_df['ID'] = IDS\n",
    "write_csv(\"results/approach3\",\"gbm_rfr_etr_best_combined\",out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried extra trees regressor single models, combined with gbms, combined with rfr and gbms but still it did not beat my public LB score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Its time to implement stacking with the best rfr and etr models worked for me along with all 10 gbm models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stacking with GBMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [gbm1,gbm2,gbm3,gbm4,gbm5,gbm6,gbm7,gbm8,gbm9,gbm10,rfr3,rfr5,etr2]\n",
    "modelNames = [\"gbm1\",\"gbm2\",\"gbm3\",\"gbm4\",\"gbm5\",\"gbm6\",\"gbm7\",\"gbm8\",\"gbm9\",\"gbm10\",\"rfr3\",\"rfr5\",\"etr2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stage0_final_train = pd.DataFrame()\n",
    "stage0_final_test = pd.DataFrame()\n",
    "\n",
    "train_dataset = [x_train1,x_train2,x_train3,x_train4,x_train5,x_train6]\n",
    "labels = [y1,y2,y3,y4,y5,y6]\n",
    "test_dataset = [x_test1,x_test2,x_test3,x_test4,x_test5,x_test6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I will generate cross validation predictions using all the best models worked for me. I will pick featureset based on random number between 0 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm1\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58262.2414        5160.5712           27.99s\n",
      "         2       54946.2789        3227.7307           27.12s\n",
      "         3       52535.5999        2579.4598           26.35s\n",
      "         4       49504.1340        3248.9530           26.09s\n",
      "         5       47045.6470        2189.0374           26.87s\n",
      "         6       44783.3222        2271.8128           26.26s\n",
      "         7       42762.9540        2029.0562           25.97s\n",
      "         8       41302.8789        1563.2390           25.57s\n",
      "         9       39617.7171        1767.9550           26.08s\n",
      "        10       38235.6597        1129.3181           25.71s\n",
      "        20       28784.4175         447.9311           24.20s\n",
      "        30       24380.8536         217.4654           25.83s\n",
      "        40       21592.6398         101.2717           24.05s\n",
      "        50       18804.1244          87.0099           23.38s\n",
      "        60       17607.9604          83.9658           22.30s\n",
      "        70       16437.3580         130.7363           21.34s\n",
      "        80       15325.1537          87.2120           20.66s\n",
      "        90       14702.9594          31.6193           19.98s\n",
      "       100       13872.6493          98.8082           19.44s\n",
      "       200       10077.1459           3.9745           14.29s\n",
      "       300        8391.9954           2.8913            9.44s\n",
      "       400        7565.6031           2.1834            4.62s\n",
      "       500        6980.8670           6.7545            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       56768.1418        5005.6723           24.50s\n",
      "         2       53646.6445        3116.4836           23.93s\n",
      "         3       51305.6598        2382.6056           23.76s\n",
      "         4       48317.4488        3173.4360           23.56s\n",
      "         5       46549.7152        1602.9355           24.44s\n",
      "         6       44295.4602        2238.5384           23.90s\n",
      "         7       42457.2737        1917.4455           23.88s\n",
      "         8       41078.4193        1517.1941           23.59s\n",
      "         9       38897.0646        2109.7283           23.45s\n",
      "        10       37638.6279        1060.6509           23.89s\n",
      "        20       28743.6011         451.6354           23.02s\n",
      "        30       24043.1394         304.2804           22.20s\n",
      "        40       20444.2548         108.4644           21.41s\n",
      "        50       17872.1718         115.3249           20.77s\n",
      "        60       16740.3269          84.4748           20.21s\n",
      "        70       15423.8001          45.3811           19.61s\n",
      "        80       14565.4075          56.9320           19.13s\n",
      "        90       13918.9577          36.2761           18.69s\n",
      "       100       13019.4601         220.7431           18.28s\n",
      "       200        9383.0516           9.4896           13.88s\n",
      "       300        8070.1183           2.7713            9.26s\n",
      "       400        7274.8299           1.7341            4.64s\n",
      "       500        6782.0194           3.6718            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       56145.2392        4775.0617           28.08s\n",
      "         2       53230.0367        2964.5358           27.93s\n",
      "         3       50924.0622        2314.2696           26.80s\n",
      "         4       48042.6518        3049.5743           26.61s\n",
      "         5       46055.5019        2010.9627           26.80s\n",
      "         6       43798.4363        2148.2231           26.11s\n",
      "         7       42006.4524        1854.0628           25.93s\n",
      "         8       40352.5585        1771.3426           25.45s\n",
      "         9       38132.8818        2151.7523           26.05s\n",
      "        10       37153.9983         957.8979           25.85s\n",
      "        20       27934.1611         390.4061           24.57s\n",
      "        30       23430.6254         311.0000           23.83s\n",
      "        40       20527.1626         106.6778           23.00s\n",
      "        50       17601.9575          60.8322           22.25s\n",
      "        60       16142.5632          84.3051           21.61s\n",
      "        70       14841.5684          43.7916           20.98s\n",
      "        80       14047.2442          70.0759           20.52s\n",
      "        90       13402.5600          41.2034           20.00s\n",
      "       100       12698.3183         186.5756           19.54s\n",
      "       200        9234.2542          12.9004           14.31s\n",
      "       300        7835.2697           7.3600            9.13s\n",
      "       400        7157.6295           4.4146            4.45s\n",
      "       500        6665.2141          -0.2063            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       56538.0615        4816.1061           25.40s\n",
      "         2       53396.8945        3035.2382           23.52s\n",
      "         3       50933.3566        2415.4939           23.46s\n",
      "         4       47931.2682        3102.6222           23.06s\n",
      "         5       46326.2346        1609.4254           23.77s\n",
      "         6       43999.8435        2245.8246           23.11s\n",
      "         7       42200.1518        1913.7927           22.85s\n",
      "         8       40939.0001        1401.7618           22.59s\n",
      "         9       38922.6668        1778.5130           22.32s\n",
      "        10       37944.3738        1122.1739           22.33s\n",
      "        20       28940.4549         457.0944           21.35s\n",
      "        30       24058.0807         529.2177           20.39s\n",
      "        40       20587.9891         111.2427           19.74s\n",
      "        50       17937.0752          75.2616           19.18s\n",
      "        60       16733.2434          91.0589           18.66s\n",
      "        70       15514.2173          79.8280           18.12s\n",
      "        80       14639.2284         117.3068           17.76s\n",
      "        90       13896.0977          33.0896           17.33s\n",
      "       100       13108.1731         251.6325           16.92s\n",
      "       200        9118.7944           9.0549           12.64s\n",
      "       300        7807.8135           2.8203            8.40s\n",
      "       400        7040.5287           1.9237            4.18s\n",
      "       500        6593.3456          12.3234            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57418.9623        3426.9122           21.46s\n",
      "         2       54101.0434        3255.4884           22.77s\n",
      "         3       51348.5408        2691.8122           22.44s\n",
      "         4       49141.9791        2268.5938           21.99s\n",
      "         5       47347.9545        1726.8389           22.75s\n",
      "         6       45528.2278        1864.6831           22.62s\n",
      "         7       43825.5395        1695.8932           22.32s\n",
      "         8       41636.3656        2013.6985           22.11s\n",
      "         9       40472.3567        1160.6192           22.19s\n",
      "        10       39346.9486        1165.7810           22.19s\n",
      "        20       29504.5892         808.5891           21.25s\n",
      "        30       23291.3298         510.8941           20.47s\n",
      "        40       20218.7638         201.5924           19.83s\n",
      "        50       17768.0745         134.2538           19.33s\n",
      "        60       16134.9715         200.0373           18.62s\n",
      "        70       15053.8657          84.8867           17.89s\n",
      "        80       13762.1363          52.7180           17.33s\n",
      "        90       13184.3980         173.8193           16.77s\n",
      "       100       12458.7388          33.3745           16.20s\n",
      "       200        9138.9299          17.7579           11.58s\n",
      "       300        7813.7891           4.1845            7.58s\n",
      "       400        6995.6579           9.8486            3.75s\n",
      "       500        6497.0401           0.6043            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57784.7021        3977.3368           28.68s\n",
      "         2       54456.3332        3176.9814           26.40s\n",
      "         3       51345.4448        3134.0511           25.98s\n",
      "         4       48586.5303        2792.1098           25.50s\n",
      "         5       46494.6459        2010.4357           26.02s\n",
      "         6       44575.7349        1938.7771           25.75s\n",
      "         7       42319.7484        2282.9166           25.33s\n",
      "         8       40641.8309        1602.1704           25.20s\n",
      "         9       38559.1498        2183.1083           25.23s\n",
      "        10       36963.5562        1607.9609           24.95s\n",
      "        20       25875.7316         875.2713           23.85s\n",
      "        30       20935.4226         222.1401           22.82s\n",
      "        40       18549.7264          89.7632           22.23s\n",
      "        50       16956.5361         112.6914           21.62s\n",
      "        60       16008.9059          43.4097           21.02s\n",
      "        70       15085.7609          50.8367           20.56s\n",
      "        80       14145.2929         163.5027           20.09s\n",
      "        90       13344.6777          31.2730           19.68s\n",
      "       100       12762.9663         169.0416           19.15s\n",
      "       200        9371.2430          42.2550           14.18s\n",
      "       300        8085.4075           5.9251            9.36s\n",
      "       400        7323.0132           7.3325            4.66s\n",
      "       500        6821.4352          11.7445            0.00s\n",
      "gbm2\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58733.9355        4674.2690            1.09m\n",
      "         2       54868.5763        3838.8494            1.00m\n",
      "         3       51890.4391        3088.6095           58.03s\n",
      "         4       49307.0533        2682.6659           56.56s\n",
      "         5       46448.3739        2571.1685           56.97s\n",
      "         6       42984.4877        3438.6473           56.67s\n",
      "         7       40994.2207        2073.4171           56.05s\n",
      "         8       37860.2293        3123.5768           55.19s\n",
      "         9       35866.1092        2092.5878           55.22s\n",
      "        10       34250.0984        1421.6018           55.13s\n",
      "        20       23348.3274         647.4549           53.20s\n",
      "        30       18412.4255         257.6547           51.76s\n",
      "        40       15540.2250         209.5586           50.63s\n",
      "        50       13876.1772         132.7369           49.52s\n",
      "        60       12742.5589          67.9850           48.74s\n",
      "        70       11655.3682         100.9276           47.95s\n",
      "        80       10814.4990          49.7361           47.53s\n",
      "        90       10292.8548          38.0472           47.03s\n",
      "       100        9641.1911          69.7192           46.59s\n",
      "       200        7158.9676           6.4636           40.70s\n",
      "       300        6226.8637           4.1898           34.96s\n",
      "       400        5626.5899           2.1139           29.62s\n",
      "       500        5206.0313           4.7368           24.37s\n",
      "       600        4840.3855           5.1917           19.39s\n",
      "       700        4585.6294           0.4625           14.47s\n",
      "       800        4320.8148           0.8855            9.63s\n",
      "       900        4088.7686           2.3021            4.80s\n",
      "      1000        3918.0618           0.1490            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57179.5916        4529.2049            1.06m\n",
      "         2       53715.4440        3488.0890           59.52s\n",
      "         3       50792.8030        2909.6595           59.12s\n",
      "         4       47770.0499        3169.6925            1.00m\n",
      "         5       44542.6230        3071.9520           59.08s\n",
      "         6       41051.6507        3374.7918           58.15s\n",
      "         7       39404.9764        1762.4782           57.54s\n",
      "         8       36357.1768        3118.2566           57.04s\n",
      "         9       34718.6927        1613.7856           56.59s\n",
      "        10       33427.6587        1173.5714           56.23s\n",
      "        20       23568.6682         557.4069           53.86s\n",
      "        30       18368.9387         256.7512           52.54s\n",
      "        40       15380.9129         142.0236           51.22s\n",
      "        50       13456.9052          67.5537           50.29s\n",
      "        60       12316.7028          56.3375           49.35s\n",
      "        70       11237.2036          54.0082           48.48s\n",
      "        80       10445.6723          58.0618           48.01s\n",
      "        90        9994.6469          30.2811           47.44s\n",
      "       100        9498.2766          32.2512           46.93s\n",
      "       200        7053.8588           4.8495           40.77s\n",
      "       300        6083.2376           3.9477           35.13s\n",
      "       400        5517.0634          10.9030           29.69s\n",
      "       500        5121.7856           6.3442           24.46s\n",
      "       600        4788.0696           0.6594           19.40s\n",
      "       700        4574.1982           0.1764           14.43s\n",
      "       800        4340.4867          -0.3270            9.63s\n",
      "       900        4123.5118           1.2799            4.92s\n",
      "      1000        3942.7130           0.5600            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       56437.0786        4452.0548            1.27m\n",
      "         2       53145.8639        3388.4665            1.21m\n",
      "         3       50292.7950        2726.3173            1.29m\n",
      "         4       47497.0820        2975.1815            1.44m\n",
      "         5       44620.2849        2849.6122            1.47m\n",
      "         6       41189.5848        3256.0052            1.47m\n",
      "         7       39557.5330        1673.7961            1.43m\n",
      "         8       37487.3647        2151.3904            1.44m\n",
      "         9       34796.6951        2602.0874            1.41m\n",
      "        10       33407.8637        1383.2718            1.40m\n",
      "        20       22611.2983         442.1596            1.36m\n",
      "        30       17769.6801         204.8521            1.27m\n",
      "        40       15228.6531         133.7808            1.19m\n",
      "        50       13112.9722         151.9986            1.12m\n",
      "        60       12066.2045          59.5896            1.05m\n",
      "        70       11081.3981          79.2214            1.01m\n",
      "        80       10313.9177         106.5124           58.17s\n",
      "        90        9812.2339          31.5484           57.47s\n",
      "       100        9193.7931          38.7121           56.79s\n",
      "       200        6881.4052          15.7881           45.57s\n",
      "       300        5890.7109           6.8651           37.77s\n",
      "       400        5404.1255           0.0584           32.47s\n",
      "       500        5033.6769           4.3669           27.43s\n",
      "       600        4717.0500           0.2053           21.78s\n",
      "       700        4461.6102           3.4605           16.25s\n",
      "       800        4197.5562           0.4334           10.69s\n",
      "       900        4009.9837           2.0631            5.26s\n",
      "      1000        3843.7750           0.0445            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       56918.1827        4330.3098            1.05m\n",
      "         2       53403.7369        3398.4726           58.19s\n",
      "         3       50435.4080        2797.2659           57.47s\n",
      "         4       47775.6208        2824.5131           56.62s\n",
      "         5       44742.1570        2956.0993           56.42s\n",
      "         6       41176.8638        3407.3874           56.08s\n",
      "         7       39496.7907        1814.2229           55.55s\n",
      "         8       37405.7054        2186.7419           55.05s\n",
      "         9       34513.7693        2678.5798           54.79s\n",
      "        10       33404.7851        1231.6669           54.57s\n",
      "        20       23252.1792         503.2012           52.84s\n",
      "        30       18308.5420         220.9096           51.33s\n",
      "        40       15267.7703         108.5071           50.20s\n",
      "        50       13201.5972          80.3611           49.20s\n",
      "        60       12003.8759          62.1788           48.46s\n",
      "        70       11178.9159         121.6446           47.85s\n",
      "        80       10364.3694          49.4344           47.33s\n",
      "        90        9817.9739          22.1891           46.78s\n",
      "       100        9324.8598          27.2052           46.26s\n",
      "       200        6721.6735          16.7584           43.92s\n",
      "       300        5873.4233           4.8488           38.51s\n",
      "       400        5311.0461           0.8805           32.28s\n",
      "       500        4906.6531           2.7732           26.75s\n",
      "       600        4623.5513           0.0763           21.24s\n",
      "       700        4351.6287           0.2238           15.84s\n",
      "       800        4172.6293           0.5654           10.53s\n",
      "       900        3979.9100           5.0772            5.24s\n",
      "      1000        3822.6479          -0.3359            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       55897.9080        4904.1343            1.07m\n",
      "         2       52528.7847        3354.1924            1.02m\n",
      "         3       49378.0488        3007.4005           59.96s\n",
      "         4       46696.9445        2716.5581           59.68s\n",
      "         5       44353.5521        2257.6076           58.91s\n",
      "         6       41315.5358        3095.1701           58.65s\n",
      "         7       39056.6202        2256.0191           58.66s\n",
      "         8       36656.6672        2229.9162           58.39s\n",
      "         9       35446.1847        1205.0461           58.41s\n",
      "        10       34428.6104        1017.0359           57.86s\n",
      "        20       24540.3044         792.1087           56.44s\n",
      "        30       18435.8844         411.8391           54.30s\n",
      "        40       15713.8338         181.4767           52.88s\n",
      "        50       13519.9428         179.3025           51.85s\n",
      "        60       12322.1119         119.2741           50.84s\n",
      "        70       11346.4532          61.0429           49.85s\n",
      "        80       10696.8269          40.7207           49.16s\n",
      "        90       10110.8466         127.6850           48.22s\n",
      "       100        9441.7461          36.1242           47.64s\n",
      "       200        6831.0873           7.2831           41.10s\n",
      "       300        5831.4773           1.5044           35.29s\n",
      "       400        5248.0245           1.4162           29.87s\n",
      "       500        4864.8660           2.8776           24.60s\n",
      "       600        4539.7764           1.5979           19.94s\n",
      "       700        4303.3373           1.2961           15.15s\n",
      "       800        4089.5590           0.6885           10.01s\n",
      "       900        3894.3768          -0.1531            4.97s\n",
      "      1000        3718.9848           0.7984            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57569.1349        4108.3602            1.36m\n",
      "         2       53602.8142        3741.0918            1.26m\n",
      "         3       49974.7295        3715.0708            1.24m\n",
      "         4       46596.4080        3412.2052            1.22m\n",
      "         5       44261.4243        2216.3537            1.21m\n",
      "         6       41533.9005        2753.3662            1.20m\n",
      "         7       39130.2728        2400.8796            1.19m\n",
      "         8       35935.2879        3139.9231            1.17m\n",
      "         9       34100.4520        1915.3192            1.16m\n",
      "        10       32787.9886        1337.2727            1.16m\n",
      "        20       22650.0386         422.1025            1.12m\n",
      "        30       17820.1315         177.1270            1.08m\n",
      "        40       15237.9790         151.1835            1.07m\n",
      "        50       13799.3378          85.3585            1.05m\n",
      "        60       12505.1005          46.1399            1.03m\n",
      "        70       11517.7978          58.7272            1.02m\n",
      "        80       10863.8098          80.4528            1.01m\n",
      "        90       10223.7208          27.4824            1.00m\n",
      "       100        9602.3511          41.0393           59.41s\n",
      "       200        7046.8477          21.0644           51.76s\n",
      "       300        6023.5582           2.7238           45.00s\n",
      "       400        5418.6610           7.5009           38.19s\n",
      "       500        5038.6063           1.1959           31.56s\n",
      "       600        4696.7981           2.1486           25.03s\n",
      "       700        4423.6002           1.3149           19.01s\n",
      "       800        4191.1536           1.3043           12.61s\n",
      "       900        4006.3996           3.6162            6.26s\n",
      "      1000        3846.0553           0.6058            0.00s\n",
      "gbm3\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       60926.6161        2494.3065            1.13m\n",
      "         2       59178.5659        1645.2653            1.08m\n",
      "         3       57782.1923        1521.8613            1.05m\n",
      "         4       56199.8371        1855.8062            1.03m\n",
      "         5       54819.0462        1114.9135            1.01m\n",
      "         6       52985.6517        1777.8229           59.81s\n",
      "         7       51448.3306        1570.1542           59.40s\n",
      "         8       50357.6428        1215.9690           59.39s\n",
      "         9       48740.0537        1737.1393           59.26s\n",
      "        10       47496.5710         962.4376           59.02s\n",
      "        20       37913.7069         545.8138           57.75s\n",
      "        30       32142.0596         402.7148           56.98s\n",
      "        40       27423.5999         260.7940           56.35s\n",
      "        50       24061.6538         212.5978           55.47s\n",
      "        60       22210.8236         120.8503           54.63s\n",
      "        70       20618.4102          64.8099           53.85s\n",
      "        80       19192.4696          59.4211           53.29s\n",
      "        90       18373.5319          52.2558           52.95s\n",
      "       100       17544.2950         106.9085           52.50s\n",
      "       200       12399.5790          22.0758           48.59s\n",
      "       300       10234.2342          13.3929           44.67s\n",
      "       400        9090.4231           1.6071           40.61s\n",
      "       500        8266.9856           5.3839           37.11s\n",
      "       600        7715.7978           1.3947           33.66s\n",
      "       700        7391.4248           3.5137           29.93s\n",
      "       800        7032.5630           0.7585           26.27s\n",
      "       900        6737.3939          -0.0814           22.45s\n",
      "      1000        6536.7442           0.4609           18.66s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59319.8213        2445.4196            1.16m\n",
      "         2       57771.9445        1551.1239            1.07m\n",
      "         3       56386.6491        1401.4573            1.04m\n",
      "         4       54763.5198        1840.7179            1.03m\n",
      "         5       53530.1824        1068.0679            1.02m\n",
      "         6       51882.6699        1571.5834            1.01m\n",
      "         7       50563.9385        1442.7074            1.00m\n",
      "         8       49557.4009        1157.1154           59.80s\n",
      "         9       47843.3742        1679.9758           59.63s\n",
      "        10       46633.8702         977.7505           59.60s\n",
      "        20       37584.5145         508.2163           59.48s\n",
      "        30       31828.6183         348.6399           58.51s\n",
      "        40       27747.4907         274.0780           57.70s\n",
      "        50       24159.8297         154.8774           56.73s\n",
      "        60       22141.0929         114.9560           55.96s\n",
      "        70       20596.5618          80.6155           55.08s\n",
      "        80       19052.7725         157.8436           54.54s\n",
      "        90       18167.5187          53.0878           54.23s\n",
      "       100       17254.6238          93.6915           53.70s\n",
      "       200       11973.3438          13.0646           49.73s\n",
      "       300       10074.3919           6.5952           45.67s\n",
      "       400        8918.2612           6.6370           41.70s\n",
      "       500        8178.7422           5.1916           37.71s\n",
      "       600        7607.4775           0.6709           34.33s\n",
      "       700        7304.7879           2.9416           31.02s\n",
      "       800        6992.5300           0.6930           27.22s\n",
      "       900        6726.1173           0.1771           23.61s\n",
      "      1000        6531.0336           1.2747           19.89s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58507.9038        2376.6226            1.24m\n",
      "         2       57093.1633        1479.3924            1.69m\n",
      "         3       55692.2382        1340.8101            1.82m\n",
      "         4       54113.0067        1768.8038            1.78m\n",
      "         5       52861.8850        1275.3826            1.63m\n",
      "         6       51229.7023        1490.8685            1.51m\n",
      "         7       49880.7975        1406.9151            1.43m\n",
      "         8       48739.9537        1271.3315            1.38m\n",
      "         9       46977.0671        1663.8022            1.34m\n",
      "        10       46027.2451         913.3150            1.30m\n",
      "        20       36695.5762         485.4274            1.26m\n",
      "        30       31049.1008         411.2094            1.23m\n",
      "        40       26758.9492         261.0231            1.15m\n",
      "        50       23364.3311         191.6117            1.10m\n",
      "        60       21603.7643         107.4139            1.06m\n",
      "        70       20055.5176          78.6872            1.03m\n",
      "        80       18796.7293         129.4394            1.01m\n",
      "        90       17951.9016          53.4671           59.48s\n",
      "       100       17011.8995         101.2140           58.47s\n",
      "       200       12023.4418          20.3498           52.52s\n",
      "       300        9917.9603          10.0653           49.39s\n",
      "       400        8707.7792           2.8991           45.29s\n",
      "       500        7956.6338          12.8933           41.01s\n",
      "       600        7473.1460           0.2339           37.28s\n",
      "       700        7122.3696           2.0487           33.41s\n",
      "       800        6809.6816           0.3846           29.00s\n",
      "       900        6523.8690           7.4910           24.91s\n",
      "      1000        6342.2480           0.9513           21.28s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59001.7783        2371.6874            1.17m\n",
      "         2       57433.3662        1485.1395            1.07m\n",
      "         3       55989.4107        1361.1122            1.05m\n",
      "         4       54276.2527        1798.9666            1.03m\n",
      "         5       52976.0489        1255.3262            1.02m\n",
      "         6       51334.3958        1525.7574            1.01m\n",
      "         7       50060.7333        1435.1108            1.00m\n",
      "         8       48885.7568        1285.5668           59.39s\n",
      "         9       46950.8471        1684.4626           59.21s\n",
      "        10       46190.2605         924.9119           59.18s\n",
      "        20       36922.3394         513.7215           58.13s\n",
      "        30       31162.6976         419.6913           57.46s\n",
      "        40       26915.2450         264.2632           56.88s\n",
      "        50       23534.9820         162.4571           56.00s\n",
      "        60       21528.6721         117.1839           55.14s\n",
      "        70       20037.4485          75.6756           54.37s\n",
      "        80       18494.7957          90.8993           53.89s\n",
      "        90       17568.8999          51.7301           53.43s\n",
      "       100       16787.3136         134.5968           52.88s\n",
      "       200       11825.4488          19.5087           48.91s\n",
      "       300        9730.6536          10.5236           45.09s\n",
      "       400        8667.8683           6.0571           41.13s\n",
      "       500        7968.3976           4.1086           37.13s\n",
      "       600        7444.6166           2.7391           33.29s\n",
      "       700        7052.7792           4.1695           29.49s\n",
      "       800        6737.7373           0.3431           25.76s\n",
      "       900        6463.9166           7.6578           21.98s\n",
      "      1000        6284.3583           1.7432           18.25s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59146.2017        1712.4549            1.16m\n",
      "         2       57409.1964        1708.9572            1.07m\n",
      "         3       55837.4268        1479.0466            1.05m\n",
      "         4       54443.4857        1405.9814            1.03m\n",
      "         5       53354.0146        1039.3111            1.02m\n",
      "         6       52092.1039        1328.0359            1.03m\n",
      "         7       50983.5258        1154.7457            1.03m\n",
      "         8       49366.1343        1435.1754            1.03m\n",
      "         9       48349.8561        1007.9604            1.02m\n",
      "        10       47523.6714         915.2622            1.01m\n",
      "        20       38348.1795         723.1499           59.75s\n",
      "        30       31836.4596         603.5134           57.95s\n",
      "        40       28308.1975         250.4514           56.91s\n",
      "        50       25501.1390         388.1771           56.21s\n",
      "        60       23154.2273         317.3090           55.61s\n",
      "        70       21280.5010          89.9914           54.91s\n",
      "        80       19566.8277          90.1606           54.37s\n",
      "        90       18596.8591         187.9771           53.74s\n",
      "       100       17375.3096          47.0683           53.23s\n",
      "       200       12035.6499          32.6701           48.88s\n",
      "       300        9919.5160           8.5788           45.05s\n",
      "       400        8601.2100           5.9506           41.16s\n",
      "       500        7787.8858           6.7566           37.27s\n",
      "       600        7286.3952           2.5410           33.31s\n",
      "       700        6895.0439           1.0790           29.50s\n",
      "       800        6615.2093           2.9381           25.69s\n",
      "       900        6405.1063           0.3290           21.92s\n",
      "      1000        6173.5499           1.1640           18.21s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59830.4489        1907.5678            1.51m\n",
      "         2       58005.8130        1644.5440            1.39m\n",
      "         3       56248.4533        1826.9201            1.36m\n",
      "         4       54611.5445        1616.0358            1.33m\n",
      "         5       53330.8031        1248.2407            1.32m\n",
      "         6       51953.6742        1400.7639            1.31m\n",
      "         7       50407.0594        1571.2255            1.29m\n",
      "         8       49170.2508        1174.2665            1.28m\n",
      "         9       47652.2458        1619.5938            1.27m\n",
      "        10       46219.2570        1499.7225            1.26m\n",
      "        20       36024.9451         873.5328            1.24m\n",
      "        30       29666.0955         384.6163            1.21m\n",
      "        40       26079.0309         221.0322            1.19m\n",
      "        50       23598.6311         212.3582            1.18m\n",
      "        60       21389.1825          83.3350            1.17m\n",
      "        70       19910.5449          78.4155            1.16m\n",
      "        80       18571.9355         167.0680            1.15m\n",
      "        90       17603.7873          71.4627            1.14m\n",
      "       100       16727.9736          86.7513            1.13m\n",
      "       200       12028.5347          29.4704            1.03m\n",
      "       300        9897.3994          24.1728           57.20s\n",
      "       400        8679.7169          25.3111           52.40s\n",
      "       500        8039.9267           8.8838           47.29s\n",
      "       600        7559.2840           3.2971           42.38s\n",
      "       700        7224.7621           0.4140           37.55s\n",
      "       800        6888.2513           2.1309           32.76s\n",
      "       900        6648.9425           2.9077           28.01s\n",
      "      1000        6463.2220           0.6929           23.31s\n",
      "gbm4\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       60942.2835        2478.7485            1.73m\n",
      "         2       58085.1099        2720.9443            1.67m\n",
      "         3       56341.7569        1886.9315            1.68m\n",
      "         4       54697.6831        1888.0852            1.65m\n",
      "         5       52276.5743        2192.0794            1.62m\n",
      "         6       50544.8932        1705.5613            1.62m\n",
      "         7       48495.5356        2042.3432            1.61m\n",
      "         8       46685.2316        1932.5887            1.60m\n",
      "         9       44404.2048        2384.3364            1.58m\n",
      "        10       42820.1804        1347.3740            1.58m\n",
      "        20       33062.7386         731.0606            1.58m\n",
      "        30       26276.7755         319.7570            1.57m\n",
      "        40       22235.7139         225.3587            1.51m\n",
      "        50       19436.2158         287.3950            1.45m\n",
      "        60       17937.9568         160.2925            1.39m\n",
      "        70       16321.2038         132.9672            1.36m\n",
      "        80       15271.1680          47.7425            1.32m\n",
      "        90       14422.1706          34.0454            1.30m\n",
      "       100       13683.9247         106.1553            1.28m\n",
      "       200        9728.3442          11.5669            1.14m\n",
      "       300        7982.5661          10.5049            1.03m\n",
      "       400        7008.1868           3.8580           57.49s\n",
      "       500        6424.5761           3.1451           51.48s\n",
      "       600        5985.4112           1.4441           45.76s\n",
      "       700        5706.6359           3.5639           40.21s\n",
      "       800        5385.8171           1.5613           34.94s\n",
      "       900        5132.9852           0.8424           29.71s\n",
      "      1000        4945.6385           0.5875           24.60s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59447.4998        2284.3353            1.40m\n",
      "         2       56925.0893        2518.1428            1.37m\n",
      "         3       55063.8665        1866.1560            1.36m\n",
      "         4       52990.9485        2244.9903            1.34m\n",
      "         5       51359.3172        1489.1313            1.32m\n",
      "         6       49555.8211        1723.8922            1.32m\n",
      "         7       47653.9927        1980.0934            1.31m\n",
      "         8       45969.9855        1800.1259            1.30m\n",
      "         9       43540.6002        2429.9688            1.29m\n",
      "        10       42065.9796        1304.6747            1.29m\n",
      "        20       32694.4631         720.7667            1.29m\n",
      "        30       26063.0891         272.5704            1.28m\n",
      "        40       22316.8659         213.1125            1.27m\n",
      "        50       19962.8453         234.4397            1.26m\n",
      "        60       18087.7388         140.9606            1.24m\n",
      "        70       16538.8131         144.0390            1.23m\n",
      "        80       15541.9806         113.4882            1.22m\n",
      "        90       14618.3214          38.1526            1.20m\n",
      "       100       13686.9544         107.0391            1.19m\n",
      "       200        9442.6505          23.9759            1.09m\n",
      "       300        7743.0395           9.2347            1.01m\n",
      "       400        6838.6449           7.6562           54.96s\n",
      "       500        6324.2769           5.4015           49.50s\n",
      "       600        5891.9039           3.6127           44.30s\n",
      "       700        5622.0717           1.5257           39.14s\n",
      "       800        5362.0452           0.4662           34.06s\n",
      "       900        5102.8621           0.2196           29.07s\n",
      "      1000        4914.4537           0.8367           24.21s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58567.4899        2299.6188            1.39m\n",
      "         2       56093.9477        2537.0479            1.34m\n",
      "         3       54244.8044        1753.2264            1.34m\n",
      "         4       52309.3757        2122.5688            1.32m\n",
      "         5       50387.9288        1953.6806            1.30m\n",
      "         6       48777.7319        1457.6860            1.30m\n",
      "         7       47416.9814        1400.8058            1.29m\n",
      "         8       45696.0796        1823.6230            1.29m\n",
      "         9       43958.1500        1649.9060            1.28m\n",
      "        10       42682.4226        1270.7888            1.28m\n",
      "        20       32963.5688         698.7121            1.27m\n",
      "        30       26388.3640         298.8240            1.27m\n",
      "        40       22599.5509         201.6079            1.25m\n",
      "        50       20046.0402         271.7679            1.24m\n",
      "        60       18268.5134         161.0742            1.22m\n",
      "        70       16798.7505         153.2798            1.20m\n",
      "        80       15805.2835          36.6069            1.19m\n",
      "        90       15039.5043          28.6663            1.18m\n",
      "       100       14150.3276         107.5080            1.17m\n",
      "       200        9642.6068          11.5671            1.07m\n",
      "       300        7817.7234          11.5227           59.21s\n",
      "       400        6743.1269           3.6026           54.11s\n",
      "       500        6149.2209           4.2585           48.90s\n",
      "       600        5739.1676           1.2009           43.76s\n",
      "       700        5438.4605           2.8270           38.73s\n",
      "       800        5178.2528           1.3435           33.86s\n",
      "       900        4967.5124           3.6819           28.92s\n",
      "      1000        4789.0041           0.5660           24.03s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59105.5610        2234.8627            1.45m\n",
      "         2       56429.5728        2577.5688            1.40m\n",
      "         3       54503.4042        1818.8486            1.39m\n",
      "         4       52412.2952        2163.4252            1.44m\n",
      "         5       50370.9130        2013.5840            1.43m\n",
      "         6       48619.1422        1615.8548            1.42m\n",
      "         7       46825.2069        1951.7730            1.41m\n",
      "         8       45151.3491        1758.5015            1.40m\n",
      "         9       42504.0869        2426.5795            1.38m\n",
      "        10       41391.3318        1259.9463            1.39m\n",
      "        20       31644.3844         734.6159            1.40m\n",
      "        30       25010.6468         303.8229            1.42m\n",
      "        40       21141.8254         204.9427            1.45m\n",
      "        50       18582.4920         217.5938            1.44m\n",
      "        60       16837.3696         130.4232            1.43m\n",
      "        70       15483.6129         123.0241            1.47m\n",
      "        80       14576.2922          72.7311            1.52m\n",
      "        90       13824.8778          28.8700            1.49m\n",
      "       100       12998.0936         123.1069            1.50m\n",
      "       200        9188.3907          14.2388            1.34m\n",
      "       300        7587.4051           9.3465            1.25m\n",
      "       400        6671.9964           3.0967            1.12m\n",
      "       500        6053.0601           6.3923            1.00m\n",
      "       600        5675.9598           1.0694           53.29s\n",
      "       700        5322.0816           1.1381           47.78s\n",
      "       800        5107.8771           1.1692           41.20s\n",
      "       900        4887.3420           2.7328           34.93s\n",
      "      1000        4736.4192           0.4278           29.25s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58336.5666        2530.3000            1.65m\n",
      "         2       56047.4323        2218.6073            1.55m\n",
      "         3       53587.9198        2348.9759            1.47m\n",
      "         4       52190.9886        1421.1226            1.49m\n",
      "         5       50485.2155        1654.7085            1.50m\n",
      "         6       48903.0490        1661.5995            1.49m\n",
      "         7       47582.7995        1365.8610            1.49m\n",
      "         8       45978.5766        1387.2977            1.50m\n",
      "         9       44764.1148        1207.1579            1.48m\n",
      "        10       43497.7375        1326.6731            1.48m\n",
      "        20       33333.2572         951.1081            1.43m\n",
      "        30       26156.2690         558.5920            1.41m\n",
      "        40       22613.9110         516.9063            1.40m\n",
      "        50       20114.0032         328.0832            1.37m\n",
      "        60       18199.4409         168.8303            1.38m\n",
      "        70       16795.4444         189.2782            1.36m\n",
      "        80       15158.7056          36.7297            1.37m\n",
      "        90       14122.8489          51.8858            1.35m\n",
      "       100       13052.8221         133.6626            1.34m\n",
      "       200        8970.5690          11.5468            1.19m\n",
      "       300        7424.2662           4.7944            1.09m\n",
      "       400        6551.2343           2.8176           59.51s\n",
      "       500        5962.8808           4.0076           56.94s\n",
      "       600        5585.4345           2.6592           51.39s\n",
      "       700        5279.3055           4.6709           44.79s\n",
      "       800        5031.1153           1.3364           38.71s\n",
      "       900        4818.9376           0.3457           33.01s\n",
      "      1000        4653.7638           1.7105           27.95s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59320.2209        2434.2261            2.28m\n",
      "         2       56933.7850        2211.1458            1.98m\n",
      "         3       55212.5881        1800.4191            1.89m\n",
      "         4       52985.1526        2216.9555            1.83m\n",
      "         5       50931.2022        1973.3928            1.81m\n",
      "         6       49552.5036        1435.5943            1.79m\n",
      "         7       48165.9210        1388.3362            1.78m\n",
      "         8       46547.2873        1573.3852            1.77m\n",
      "         9       45228.8862        1398.5586            1.76m\n",
      "        10       44058.5852        1213.0729            1.76m\n",
      "        20       33137.1006         734.4786            1.71m\n",
      "        30       26480.0259         472.2239            1.71m\n",
      "        40       23156.0437         304.0980            1.72m\n",
      "        50       20595.9549         226.4530            1.73m\n",
      "        60       18787.8935          89.5652            1.75m\n",
      "        70       17334.2347         112.9232            1.75m\n",
      "        80       16231.1750         117.0693            1.74m\n",
      "        90       15076.1126          60.5488            1.72m\n",
      "       100       14173.4433         120.6582            1.71m\n",
      "       200        9444.0747          39.4912            1.51m\n",
      "       300        7704.7274           3.0943            1.39m\n",
      "       400        6787.8464           8.2917            1.27m\n",
      "       500        6246.6484           4.0622            1.15m\n",
      "       600        5832.4788           0.9225            1.04m\n",
      "       700        5555.1009           3.0620           55.35s\n",
      "       800        5265.4853           1.5155           48.97s\n",
      "       900        5041.3274           0.6248           41.97s\n",
      "      1000        4895.3508           0.6105           35.23s\n",
      "gbm5\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       60198.8570        3258.6756           49.71s\n",
      "         2       57840.9803        2228.0556           50.02s\n",
      "         3       55985.5575        2025.5257           48.82s\n",
      "         4       54064.5600        2131.5606           48.31s\n",
      "         5       52082.9490        1821.8106           47.10s\n",
      "         6       49619.3278        2385.8181           47.16s\n",
      "         7       48371.2352        1296.8478           47.05s\n",
      "         8       47021.2736        1416.8667           46.90s\n",
      "         9       45302.1605        1834.6651           46.66s\n",
      "        10       43919.7831        1162.4525           46.89s\n",
      "        20       34741.3189         775.0490           46.28s\n",
      "        30       28268.1275         295.8209           45.15s\n",
      "        40       24517.1688         380.4344           44.13s\n",
      "        50       22220.0707         155.2655           43.28s\n",
      "        60       20612.8162         188.1955           42.45s\n",
      "        70       19250.1099          66.7713           41.81s\n",
      "        80       18244.6771          46.6252           41.12s\n",
      "        90       17431.6387          51.7497           40.45s\n",
      "       100       16591.8896         108.9135           39.88s\n",
      "       200       11991.2691          19.0185           34.98s\n",
      "       300        9912.3043          14.1553           30.89s\n",
      "       400        8630.7206           9.3660           26.75s\n",
      "       500        7977.3306           4.8116           21.96s\n",
      "       600        7450.8507           2.7820           17.20s\n",
      "       700        7086.6640           1.0979           12.77s\n",
      "       800        6779.1415           0.4919            8.45s\n",
      "       900        6499.2560           3.5218            4.26s\n",
      "      1000        6294.0995           0.1672            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58639.1798        3129.0581           53.07s\n",
      "         2       56482.0256        2141.1791           54.23s\n",
      "         3       54590.9220        1926.7488           54.15s\n",
      "         4       52743.9990        2013.7207           54.02s\n",
      "         5       50018.5940        2559.5169           52.64s\n",
      "         6       47627.1214        2284.7183           52.72s\n",
      "         7       46520.6749        1232.3095           52.87s\n",
      "         8       45261.8395        1363.9847           52.77s\n",
      "         9       43912.9005        1349.5146           52.39s\n",
      "        10       42680.1272        1071.6888           52.63s\n",
      "        20       34426.6143         712.8293           51.16s\n",
      "        30       28008.5791         493.4161           50.87s\n",
      "        40       24228.9934         193.5582           50.39s\n",
      "        50       22164.1428         149.2443           50.73s\n",
      "        60       20412.8080         204.6972           51.11s\n",
      "        70       18879.5031          69.5350           51.00s\n",
      "        80       17982.7057          33.4467           51.03s\n",
      "        90       17219.9682          47.9972           49.63s\n",
      "       100       16264.3857         124.6094           48.01s\n",
      "       200       11950.0786          11.1921           37.54s\n",
      "       300        9668.5529          11.0752           32.77s\n",
      "       400        8537.8539           7.8328           27.67s\n",
      "       500        7841.2583           7.9312           22.62s\n",
      "       600        7293.6960           1.1956           17.98s\n",
      "       700        6978.2993           2.1049           13.46s\n",
      "       800        6689.7665           1.8179            8.94s\n",
      "       900        6400.4722           0.2029            4.40s\n",
      "      1000        6217.7725           0.8880            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57826.1788        3078.9311            1.13m\n",
      "         2       55812.3870        2063.2062            1.08m\n",
      "         3       53885.7118        1865.5284            1.01m\n",
      "         4       52086.9188        1969.1739           57.79s\n",
      "         5       49548.5598        2553.6985           54.94s\n",
      "         6       47333.8235        2040.3931           53.59s\n",
      "         7       46001.1124        1407.3694           52.28s\n",
      "         8       44668.2859        1411.7732           51.82s\n",
      "         9       43322.3810        1287.3481           51.66s\n",
      "        10       42285.4616        1023.3958           51.48s\n",
      "        20       33892.0070         708.5577           53.56s\n",
      "        30       27897.2112         521.6371           55.33s\n",
      "        40       24219.1767         371.8603           54.20s\n",
      "        50       22045.7670         155.8690           53.19s\n",
      "        60       20222.5393         111.7736           52.87s\n",
      "        70       18816.2472         105.8094           52.52s\n",
      "        80       17987.9852          31.2208           52.22s\n",
      "        90       17112.6785          49.5155           51.39s\n",
      "       100       15939.4566         292.6097           50.95s\n",
      "       200       11535.6268          25.5758           47.42s\n",
      "       300        9475.9497          10.6305           42.86s\n",
      "       400        8343.2876          13.3203           36.08s\n",
      "       500        7642.5774           7.4552           29.53s\n",
      "       600        7081.5110           1.6593           23.29s\n",
      "       700        6708.5105           5.0336           16.82s\n",
      "       800        6467.7508           0.7428           10.87s\n",
      "       900        6194.8480           4.6536            5.32s\n",
      "      1000        6040.4141           1.2276            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58271.6697        3069.4339           44.67s\n",
      "         2       56042.1698        2133.7620           42.97s\n",
      "         3       54064.9087        1897.5889           43.08s\n",
      "         4       52131.5722        1995.3621           43.37s\n",
      "         5       50126.6855        1994.6394           43.21s\n",
      "         6       47670.2493        2239.5948           43.97s\n",
      "         7       46603.2603        1260.4454           44.38s\n",
      "         8       45258.5342        1415.0155           44.60s\n",
      "         9       43375.6112        1665.1070           44.60s\n",
      "        10       42515.0241        1032.6987           45.19s\n",
      "        20       34108.3872         687.0947           44.64s\n",
      "        30       27304.3390         483.5719           44.37s\n",
      "        40       23581.4503         237.1725           42.67s\n",
      "        50       21033.9362         149.0854           41.31s\n",
      "        60       19325.9228         109.0327           40.38s\n",
      "        70       18002.6256         124.8093           39.63s\n",
      "        80       17126.0281          66.0393           38.88s\n",
      "        90       16075.9494          42.0145           38.43s\n",
      "       100       15206.7556         206.4863           37.82s\n",
      "       200       11255.0078          23.8652           34.49s\n",
      "       300        9194.4106           7.3220           31.30s\n",
      "       400        8156.3703           1.8873           25.92s\n",
      "       500        7484.0731           2.0328           21.29s\n",
      "       600        7000.8982           1.4397           16.95s\n",
      "       700        6633.0451           1.3264           12.73s\n",
      "       800        6379.1216           0.7637            8.39s\n",
      "       900        6134.6898           4.4707            4.18s\n",
      "      1000        5973.0978          -0.0601            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58499.6152        2404.2550           51.30s\n",
      "         2       56372.0891        2104.5131           47.50s\n",
      "         3       54367.4732        1814.9590           46.89s\n",
      "         4       52809.1615        1603.8210           46.03s\n",
      "         5       51036.9573        1727.0768           45.93s\n",
      "         6       48769.9933        2356.5510           45.55s\n",
      "         7       47518.1975        1324.1363           48.20s\n",
      "         8       45971.9593        1359.0851           48.07s\n",
      "         9       44534.9703        1425.1137           48.05s\n",
      "        10       43006.7598        1568.8206           49.14s\n",
      "        20       34583.3927         483.5979           47.44s\n",
      "        30       28648.2828         567.7485           47.32s\n",
      "        40       25267.4956         233.3137           47.36s\n",
      "        50       22710.5197         144.6039           45.65s\n",
      "        60       20864.8620         275.8191           44.38s\n",
      "        70       18974.1293         343.1228           43.57s\n",
      "        80       17728.0090          42.7247           42.56s\n",
      "        90       16887.8054          54.7421           41.81s\n",
      "       100       15922.5241          39.8719           40.73s\n",
      "       200       11282.5295          15.1103           37.88s\n",
      "       300        9335.7147          10.9339           32.52s\n",
      "       400        8198.5278           4.7833           27.49s\n",
      "       500        7490.1906           1.7059           22.73s\n",
      "       600        6998.8419           1.2928           18.05s\n",
      "       700        6686.4060           1.4662           13.38s\n",
      "       800        6402.5000           3.2516            8.86s\n",
      "       900        6167.3806           0.8368            4.40s\n",
      "      1000        5976.0994           2.1989            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59317.6672        2437.2684            1.15m\n",
      "         2       55472.6595        3706.7161            1.06m\n",
      "         3       53592.9595        1955.9963            1.04m\n",
      "         4       51701.7858        1886.2592            1.04m\n",
      "         5       49765.4576        1851.6527            1.04m\n",
      "         6       48412.7923        1368.8557            1.04m\n",
      "         7       47108.9039        1357.3405            1.04m\n",
      "         8       45682.6748        1343.2311            1.04m\n",
      "         9       44337.2633        1433.7632            1.04m\n",
      "        10       43264.0075        1138.8625            1.06m\n",
      "        20       32316.5410         543.4399            1.03m\n",
      "        30       26525.8706         303.3782            1.00m\n",
      "        40       23438.2028         440.2809           59.50s\n",
      "        50       21260.2463         156.6185           58.94s\n",
      "        60       19729.7274          99.0090           57.92s\n",
      "        70       18427.8646          68.0938           57.16s\n",
      "        80       17480.5027          76.6137           56.52s\n",
      "        90       16742.4505          52.0977           56.00s\n",
      "       100       15959.3179          55.2127           55.04s\n",
      "       200       11333.9266          37.3058           47.78s\n",
      "       300        9333.0850           4.5223           42.34s\n",
      "       400        8301.5568           1.2414           35.59s\n",
      "       500        7634.7135           4.9989           28.71s\n",
      "       600        7139.8817           0.9738           22.45s\n",
      "       700        6833.9942           2.6298           16.57s\n",
      "       800        6488.6821           0.9369           11.11s\n",
      "       900        6225.3782           0.6841            5.52s\n",
      "      1000        6042.8579           0.8034            0.00s\n",
      "gbm6\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       60562.1501        2864.0925            1.09m\n",
      "         2       57983.2724        2502.7931            1.01m\n",
      "         3       55921.5011        2201.6015           59.52s\n",
      "         4       53815.6171        2320.8821           58.53s\n",
      "         5       51524.3965        2007.7523           58.61s\n",
      "         6       48926.8253        2578.6261           58.27s\n",
      "         7       47340.8244        1639.3676           57.67s\n",
      "         8       45558.9815        1870.4810           57.25s\n",
      "         9       43909.2254        1775.2237           57.18s\n",
      "        10       42246.0661        1415.5588           56.84s\n",
      "        20       30739.6766         739.4503           55.34s\n",
      "        30       24771.4365         305.8559           54.39s\n",
      "        40       21450.9958         205.6909           53.44s\n",
      "        50       18966.1650         140.2844           52.35s\n",
      "        60       17111.1410          91.2488           51.48s\n",
      "        70       15601.1178         180.3851           51.27s\n",
      "        80       14371.7579         138.1615           50.76s\n",
      "        90       13565.6760          97.2196           50.00s\n",
      "       100       12770.7010          69.1968           49.51s\n",
      "       200        8837.0900          10.5814           43.94s\n",
      "       300        7351.7058          14.0968           37.89s\n",
      "       400        6582.6999           3.7786           31.99s\n",
      "       500        6062.8495           4.7738           26.49s\n",
      "       600        5662.5847           2.1824           21.23s\n",
      "       700        5383.2156           1.6958           15.94s\n",
      "       800        5115.4754           1.1833           10.78s\n",
      "       900        4882.2278           0.2582            5.33s\n",
      "      1000        4679.3878           0.3398            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58951.3605        2774.7340            1.48m\n",
      "         2       56682.8743        2276.4318            1.27m\n",
      "         3       54678.2027        2012.1421            1.24m\n",
      "         4       52682.2532        2193.7057            1.21m\n",
      "         5       50613.4190        1896.5874            1.19m\n",
      "         6       47895.5031        2591.6588            1.18m\n",
      "         7       46530.9613        1490.5583            1.17m\n",
      "         8       44050.2763        2585.0543            1.15m\n",
      "         9       42341.9941        1706.0674            1.14m\n",
      "        10       40925.0909        1249.8906            1.15m\n",
      "        20       30767.5045         539.6281            1.10m\n",
      "        30       25096.6914         280.1204            1.07m\n",
      "        40       21434.1807         230.6258            1.07m\n",
      "        50       18673.9646         144.7179            1.05m\n",
      "        60       16952.9963          87.8141            1.03m\n",
      "        70       15380.5594         101.5438            1.01m\n",
      "        80       14518.9825          64.5517           59.63s\n",
      "        90       13637.1265          41.3258           59.21s\n",
      "       100       12942.4894          56.9847           57.86s\n",
      "       200        8618.5187          16.6353           53.18s\n",
      "       300        7252.6608           4.7972           46.05s\n",
      "       400        6573.4002           1.6773           38.00s\n",
      "       500        6055.3977           4.5279           30.96s\n",
      "       600        5684.8814          -0.1251           24.06s\n",
      "       700        5418.7276           2.9320           18.22s\n",
      "       800        5145.9295           0.9162           12.41s\n",
      "       900        4901.1744           1.0981            6.10s\n",
      "      1000        4709.7451           0.6152            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58149.1249        2727.4064            1.26m\n",
      "         2       56018.6859        2206.5070            1.24m\n",
      "         3       54048.1932        1883.3956            1.18m\n",
      "         4       52272.2224        1973.4034            1.12m\n",
      "         5       50040.4533        2215.6473            1.08m\n",
      "         6       47400.2603        2476.2369            1.06m\n",
      "         7       45980.1533        1479.3583            1.04m\n",
      "         8       43584.4179        2525.1578            1.02m\n",
      "         9       41466.9613        2013.7470            1.00m\n",
      "        10       40312.2617        1138.8040            1.01m\n",
      "        20       29530.8342         657.5940            1.03m\n",
      "        30       24113.7578         313.3614            1.03m\n",
      "        40       20565.4861         204.3136           59.68s\n",
      "        50       17835.1137         137.5253           58.39s\n",
      "        60       16206.8112          88.7667           56.96s\n",
      "        70       14792.5167         105.4587           55.63s\n",
      "        80       14027.4741          44.4020           55.05s\n",
      "        90       13174.8835          42.3969           54.79s\n",
      "       100       12368.3257          67.5471           53.97s\n",
      "       200        8574.4209          12.5343           46.97s\n",
      "       300        7081.4448           3.0176           40.39s\n",
      "       400        6305.3657           9.9521           33.83s\n",
      "       500        5775.6434           8.6994           28.76s\n",
      "       600        5444.8489           0.6445           23.06s\n",
      "       700        5180.0474           2.0093           17.39s\n",
      "       800        4913.6720           0.9571           11.52s\n",
      "       900        4687.3400           5.2661            5.75s\n",
      "      1000        4512.4913          -0.1168            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58654.9749        2653.4735            1.09m\n",
      "         2       56327.0046        2220.6082            1.01m\n",
      "         3       54280.0435        1912.8764           59.86s\n",
      "         4       52187.9240        2215.5446           59.54s\n",
      "         5       49878.2406        2270.9613           59.05s\n",
      "         6       47272.8821        2434.0334           58.38s\n",
      "         7       45892.6816        1518.5637           57.96s\n",
      "         8       44248.5445        1765.7665           57.45s\n",
      "         9       42226.5748        1806.2577           57.04s\n",
      "        10       41157.8495        1210.1855           56.93s\n",
      "        20       29808.7228         586.0565           55.39s\n",
      "        30       24091.4913         448.9733           54.13s\n",
      "        40       20604.1592         180.5124           53.08s\n",
      "        50       17769.0928         136.1884           51.85s\n",
      "        60       16167.6799          94.1798           51.11s\n",
      "        70       14548.2623         183.6839           50.13s\n",
      "        80       13376.1786         119.8066           49.44s\n",
      "        90       12679.5766          48.4071           48.84s\n",
      "       100       11925.4976          74.1485           48.42s\n",
      "       200        8238.8725           6.6929           43.09s\n",
      "       300        6899.4859           8.0869           39.12s\n",
      "       400        6184.3139           9.1457           33.89s\n",
      "       500        5715.8296           3.4892           28.06s\n",
      "       600        5380.6688           0.4176           22.26s\n",
      "       700        5076.4919           2.7733           16.60s\n",
      "       800        4876.8796           0.6183           10.90s\n",
      "       900        4681.8876           0.2956            5.38s\n",
      "      1000        4517.0071           0.8974            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57832.5287        3005.2594            1.08m\n",
      "         2       55624.3907        2189.2240            1.02m\n",
      "         3       53425.7373        2058.5806           59.37s\n",
      "         4       51477.8025        1968.8862           59.12s\n",
      "         5       49995.3391        1412.5016           58.38s\n",
      "         6       48318.9657        1761.2363           58.03s\n",
      "         7       46341.2296        2000.9039           57.88s\n",
      "         8       44436.4525        1713.7622           57.96s\n",
      "         9       43254.6061        1172.2525           58.11s\n",
      "        10       42097.8805        1188.0179           57.35s\n",
      "        20       31298.5105         918.1847           55.67s\n",
      "        30       24598.5688         937.2728           54.25s\n",
      "        40       20576.2689         291.4840           53.06s\n",
      "        50       17879.8990         212.1731           52.23s\n",
      "        60       16154.4699         201.2144           51.18s\n",
      "        70       14862.5876          63.3450           50.28s\n",
      "        80       13512.6670          57.9084           49.69s\n",
      "        90       12779.8266         214.8111           48.84s\n",
      "       100       11987.4172          39.1686           48.21s\n",
      "       200        8265.2502           9.1231           42.23s\n",
      "       300        6904.5542           4.3927           36.67s\n",
      "       400        6145.6208           7.6537           31.04s\n",
      "       500        5700.5035           7.8581           25.67s\n",
      "       600        5317.1901           1.7198           20.69s\n",
      "       700        5040.1565           1.1134           15.57s\n",
      "       800        4769.0899           1.2426           10.39s\n",
      "       900        4546.8002          -0.0796            5.19s\n",
      "      1000        4383.7276           0.8340            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59192.8972        2517.5770            2.31m\n",
      "         2       56632.1025        2369.3799            1.86m\n",
      "         3       54202.2575        2514.7331            1.77m\n",
      "         4       51829.8441        2373.2659            1.72m\n",
      "         5       50063.9706        1696.4962            1.66m\n",
      "         6       47909.1599        2193.8741            1.61m\n",
      "         7       46072.7207        1844.1047            1.56m\n",
      "         8       44413.0857        1613.9423            1.54m\n",
      "         9       42762.8081        1745.1764            1.51m\n",
      "        10       41000.1834        1785.4610            1.49m\n",
      "        20       30367.9859         580.9464            1.51m\n",
      "        30       23868.5777         391.1746            1.52m\n",
      "        40       20560.0622         208.6249            1.43m\n",
      "        50       18217.7628         185.6440            1.37m\n",
      "        60       16424.7339         133.8492            1.33m\n",
      "        70       15156.6373          83.3488            1.28m\n",
      "        80       14081.4345         167.2132            1.25m\n",
      "        90       13230.7264          73.2959            1.22m\n",
      "       100       12477.2172          65.4452            1.20m\n",
      "       200        8694.1963          39.0248            1.08m\n",
      "       300        7157.9360           8.8749           54.54s\n",
      "       400        6409.7271           5.7874           45.36s\n",
      "       500        5902.8625           3.4256           36.38s\n",
      "       600        5503.2550           1.2881           28.92s\n",
      "       700        5226.7800           2.2103           21.29s\n",
      "       800        4971.2580           0.2466           13.97s\n",
      "       900        4777.2753           0.5167            6.93s\n",
      "      1000        4621.2696           0.4654            0.00s\n",
      "gbm7\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57640.4302        5820.8262           34.54s\n",
      "         2       53868.8228        3661.2145           36.96s\n",
      "         3       50920.6915        3140.0446           35.52s\n",
      "         4       47971.5015        3068.2164           34.24s\n",
      "         5       45271.4668        2618.9339           33.00s\n",
      "         6       42025.3512        3214.9763           32.54s\n",
      "         7       40360.2076        1712.4429           32.59s\n",
      "         8       38269.3325        2118.5322           32.86s\n",
      "         9       36420.2518        1921.0095           32.49s\n",
      "        10       35071.9310        1150.5643           32.39s\n",
      "        20       26465.1675         583.4033           31.68s\n",
      "        30       21182.0002         297.1483           30.76s\n",
      "        40       18745.1927         245.4386           29.85s\n",
      "        50       16894.6039         188.8307           29.30s\n",
      "        60       15730.7497          89.3360           29.48s\n",
      "        70       14299.0130          70.4805           29.48s\n",
      "        80       13594.1229          40.3405           29.85s\n",
      "        90       12903.6020          49.1551           29.12s\n",
      "       100       12356.5429          48.0191           28.39s\n",
      "       200        9341.0907           4.7291           23.41s\n",
      "       300        7932.2923          13.5097           19.24s\n",
      "       400        7088.9769           1.3916           15.27s\n",
      "       500        6588.2644           0.1434           11.37s\n",
      "       600        6200.9127           1.2274            7.52s\n",
      "       700        5960.2714           1.5535            3.75s\n",
      "       800        5712.4343           0.5311            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       56191.1055        5589.8367           34.04s\n",
      "         2       52680.9575        3476.0939           32.70s\n",
      "         3       49743.9247        2991.1937           31.92s\n",
      "         4       46927.1665        2910.8341           31.42s\n",
      "         5       44416.0069        2451.2712           30.65s\n",
      "         6       41113.4700        3236.3521           30.87s\n",
      "         7       39657.2331        1574.8315           30.87s\n",
      "         8       38095.3763        1644.4337           30.72s\n",
      "         9       36150.3167        1934.6338           30.48s\n",
      "        10       34844.5589        1209.1283           30.53s\n",
      "        20       26523.4715         518.4622           30.21s\n",
      "        30       21222.6018         223.9864           29.57s\n",
      "        40       18592.3380         166.4745           28.87s\n",
      "        50       16861.7148         133.2368           28.24s\n",
      "        60       15715.9371          98.4432           27.86s\n",
      "        70       14592.7736          99.8726           27.47s\n",
      "        80       13815.6171          56.6533           27.16s\n",
      "        90       13191.1871          24.1877           26.66s\n",
      "       100       12412.2625         257.2681           26.24s\n",
      "       200        9029.0496           8.9433           22.39s\n",
      "       300        7650.0310           6.2873           18.55s\n",
      "       400        6986.2472           1.3186           14.73s\n",
      "       500        6520.2025           0.3511           11.00s\n",
      "       600        6138.9756           0.8268            7.31s\n",
      "       700        5918.1120           0.0170            3.63s\n",
      "       800        5666.4525           0.1259            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       55443.8895        5501.0081           34.76s\n",
      "         2       52102.6537        3317.0233           33.36s\n",
      "         3       49150.9491        2928.5922           32.45s\n",
      "         4       44749.3152        4591.2460           31.78s\n",
      "         5       42296.0227        2501.8431           30.99s\n",
      "         6       39351.2588        2770.5118           31.19s\n",
      "         7       37742.8240        1717.6501           30.99s\n",
      "         8       35181.9072        2628.1300           30.84s\n",
      "         9       33329.7828        1736.7527           30.63s\n",
      "        10       32335.4083        1016.2741           30.77s\n",
      "        20       24773.1718         522.6379           30.36s\n",
      "        30       19617.8718         184.7603           29.66s\n",
      "        40       17644.1757         166.2882           28.93s\n",
      "        50       15810.5339         119.2403           28.34s\n",
      "        60       14614.7697          73.3198           27.99s\n",
      "        70       13386.1633         116.4313           27.71s\n",
      "        80       12813.1689          33.1407           27.36s\n",
      "        90       12154.6441          38.5062           26.90s\n",
      "       100       11566.7223          51.4510           26.47s\n",
      "       200        8588.7216           3.7305           22.58s\n",
      "       300        7373.9325           7.6768           18.70s\n",
      "       400        6737.1849           1.0992           14.88s\n",
      "       500        6300.8166           3.6606           11.09s\n",
      "       600        5933.4375           0.5197            7.36s\n",
      "       700        5701.5461           3.6333            3.67s\n",
      "       800        5474.3644           0.2988            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       55811.1688        5481.5485           35.65s\n",
      "         2       52176.9828        3534.1909           34.12s\n",
      "         3       49112.8666        2968.4722           33.44s\n",
      "         4       44618.5814        4589.4457           32.84s\n",
      "         5       42160.8722        2441.4151           31.95s\n",
      "         6       39145.1952        2875.5623           32.16s\n",
      "         7       37823.3816        1504.1769           31.98s\n",
      "         8       35277.3098        2623.0173           31.72s\n",
      "         9       33349.4901        1731.4367           31.58s\n",
      "        10       32447.0182        1038.2071           31.54s\n",
      "        20       24486.7377         797.5951           30.71s\n",
      "        30       19567.4554         341.0193           30.06s\n",
      "        40       17277.8254         209.8912           29.35s\n",
      "        50       15595.4801         108.4169           28.69s\n",
      "        60       14541.6732          65.8793           28.29s\n",
      "        70       13629.5352         112.2498           27.86s\n",
      "        80       12914.5296          50.2164           27.46s\n",
      "        90       12268.8803          42.6920           27.08s\n",
      "       100       11444.2654         203.8867           26.65s\n",
      "       200        8552.2472          12.1646           22.70s\n",
      "       300        7426.6827          10.1603           18.70s\n",
      "       400        6683.6886           3.0878           14.94s\n",
      "       500        6197.6310           3.9150           11.16s\n",
      "       600        5881.5379           0.9320            7.40s\n",
      "       700        5581.7773           1.2803            3.68s\n",
      "       800        5391.1302          -0.0141            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       56618.8671        4294.8646           37.28s\n",
      "         2       53100.5748        3441.4488           34.15s\n",
      "         3       49525.5047        3466.2754           32.86s\n",
      "         4       47261.9890        2258.6606           32.12s\n",
      "         5       44856.4026        2357.3385           32.19s\n",
      "         6       41539.2990        3389.4534           32.27s\n",
      "         7       39954.5046        1598.3302           32.03s\n",
      "         8       37130.5891        2662.9180           31.77s\n",
      "         9       35364.1440        1760.9574           31.61s\n",
      "        10       33693.2532        1682.6664           31.54s\n",
      "        20       25743.0505         364.0488           30.66s\n",
      "        30       20526.5002         327.2584           29.80s\n",
      "        40       18322.5988         234.1444           28.96s\n",
      "        50       16550.6975         138.2240           28.59s\n",
      "        60       15429.1674         125.9153           28.13s\n",
      "        70       13988.0832          92.2185           27.64s\n",
      "        80       12907.9450          38.5801           27.30s\n",
      "        90       12239.6217          32.0054           26.86s\n",
      "       100       11504.0375          37.4063           26.50s\n",
      "       200        8502.3965           9.3871           22.53s\n",
      "       300        7430.1030          -0.1735           18.58s\n",
      "       400        6756.3907           3.9114           14.71s\n",
      "       500        6292.6671           0.4939           10.99s\n",
      "       600        5938.6477           1.5384            7.30s\n",
      "       700        5634.8805           0.6676            3.64s\n",
      "       800        5433.6733           1.3929            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57397.0749        4352.1492           47.84s\n",
      "         2       51003.1694        6276.7553           43.36s\n",
      "         3       48056.8514        3015.2136           42.18s\n",
      "         4       45383.3292        2723.3971           41.84s\n",
      "         5       42672.6087        2555.2013           42.02s\n",
      "         6       40954.5175        1730.9108           41.65s\n",
      "         7       39282.3705        1760.6426           41.37s\n",
      "         8       37676.5127        1484.5258           41.20s\n",
      "         9       35333.2696        2433.3640           40.83s\n",
      "        10       34308.8156        1082.7853           40.68s\n",
      "        20       23182.9355         374.8402           39.95s\n",
      "        30       18877.1852         167.1855           38.64s\n",
      "        40       17295.7090         264.5660           37.79s\n",
      "        50       15417.8875         180.8699           37.28s\n",
      "        60       14515.6125          56.7650           36.63s\n",
      "        70       13761.5852          66.5495           36.03s\n",
      "        80       12920.0708          53.9544           35.43s\n",
      "        90       12380.2979          32.4963           34.99s\n",
      "       100       11712.0150          63.5192           34.42s\n",
      "       200        8799.8934          43.9351           29.31s\n",
      "       300        7533.6552           2.2378           24.18s\n",
      "       400        6826.0295           4.1587           19.24s\n",
      "       500        6391.6537           2.8546           14.35s\n",
      "       600        6049.9705           1.3832            9.54s\n",
      "       700        5817.9591          -0.1582            4.74s\n",
      "       800        5577.9540          -0.4111            0.00s\n",
      "gbm8\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57827.7308        5539.0306           51.33s\n",
      "         2       53845.1513        3933.8033           46.98s\n",
      "         3       50742.9735        3291.3708           45.35s\n",
      "         4       47320.3404        3497.7054           44.44s\n",
      "         5       43705.6023        3409.8103           44.06s\n",
      "         6       40172.5074        3520.9674           43.82s\n",
      "         7       38338.0373        1856.9799           43.51s\n",
      "         8       36015.2648        2396.1294           42.88s\n",
      "         9       34454.6998        1700.9238           42.60s\n",
      "        10       32973.8551        1235.5802           42.57s\n",
      "        20       22894.3620         566.6695           41.06s\n",
      "        30       19047.0928         164.5599           39.85s\n",
      "        40       15921.6579         134.6917           39.02s\n",
      "        50       14072.7880          79.6591           38.23s\n",
      "        60       12984.4188          77.1883           37.55s\n",
      "        70       12078.5098          59.2708           36.87s\n",
      "        80       11145.6991         105.8651           36.37s\n",
      "        90       10503.7621          32.0338           35.88s\n",
      "       100        9957.0371          63.6111           35.45s\n",
      "       200        7272.1230          10.4723           30.09s\n",
      "       300        6154.8496           3.7515           24.80s\n",
      "       400        5558.4990           2.3475           19.56s\n",
      "       500        5071.7853           2.5847           14.58s\n",
      "       600        4728.6432           1.1766            9.62s\n",
      "       700        4478.2458           5.3050            4.78s\n",
      "       800        4242.8024          -0.1892            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       56515.5843        5222.1383           47.59s\n",
      "         2       52772.1081        3727.9314           44.82s\n",
      "         3       49728.1609        3104.4716           44.05s\n",
      "         4       46361.5362        3489.4299           43.87s\n",
      "         5       43580.5600        2568.7032           43.74s\n",
      "         6       39741.3313        3803.7229           43.22s\n",
      "         7       37892.9550        1913.8721           43.09s\n",
      "         8       35582.5264        2372.5826           42.61s\n",
      "         9       33830.4046        1796.8486           42.54s\n",
      "        10       32420.0391        1221.4312           42.55s\n",
      "        20       22178.3531         349.1731           40.97s\n",
      "        30       17915.9907         362.0630           39.81s\n",
      "        40       15502.6919          92.8406           38.82s\n",
      "        50       13870.2980          88.4493           38.16s\n",
      "        60       12776.0006          66.2292           37.57s\n",
      "        70       11700.4024          61.9622           37.04s\n",
      "        80       10950.7454          73.8472           36.54s\n",
      "        90       10381.5519          26.9262           36.05s\n",
      "       100        9780.9084          56.4936           35.58s\n",
      "       200        7233.3781          15.0415           30.22s\n",
      "       300        6189.2748           5.3451           24.78s\n",
      "       400        5568.9290           0.6196           20.75s\n",
      "       500        5178.4300           0.5494           15.83s\n",
      "       600        4820.1702           1.0229           10.82s\n",
      "       700        4541.6119           1.2965            5.47s\n",
      "       800        4293.3595          -0.0604            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       55896.3472        4993.3123           47.74s\n",
      "         2       52117.3933        3796.5620           44.99s\n",
      "         3       49115.9700        3025.3172           44.16s\n",
      "         4       45881.8228        3378.1723           43.98s\n",
      "         5       43096.3957        2772.7049           43.56s\n",
      "         6       39606.0374        3335.1966           43.20s\n",
      "         7       37854.0553        1801.2655           42.98s\n",
      "         8       35555.2661        2369.5744           42.56s\n",
      "         9       32770.3980        2704.4730           42.49s\n",
      "        10       31547.1033        1221.4487           42.55s\n",
      "        20       21708.7921         502.1684           40.88s\n",
      "        30       17263.3871         216.1499           39.42s\n",
      "        40       14892.8702         157.3335           38.64s\n",
      "        50       13158.5613          79.7553           37.96s\n",
      "        60       12007.4261          68.8799           37.39s\n",
      "        70       10937.3172         120.6897           36.71s\n",
      "        80       10315.4028          27.3823           36.21s\n",
      "        90        9740.1971          20.7982           35.65s\n",
      "       100        9165.4948          43.1512           35.17s\n",
      "       200        6938.1292           6.2815           29.67s\n",
      "       300        5934.2677           4.9015           24.47s\n",
      "       400        5344.6787           2.9511           19.36s\n",
      "       500        4957.3828           0.7505           14.36s\n",
      "       600        4650.3527           0.8420            9.49s\n",
      "       700        4397.0868           5.4827            4.71s\n",
      "       800        4159.3927           0.0786            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       56302.8828        4983.1372           47.45s\n",
      "         2       52553.1837        3579.8651           44.60s\n",
      "         3       49408.6428        3030.8475           44.06s\n",
      "         4       46068.5102        3400.2637           43.99s\n",
      "         5       42946.1647        3032.8865           43.74s\n",
      "         6       39333.3870        3513.1532           43.37s\n",
      "         7       37681.3397        1804.9901           43.17s\n",
      "         8       35527.6141        2209.3185           42.83s\n",
      "         9       33463.0827        1866.4296           42.69s\n",
      "        10       32372.2895        1196.9975           42.54s\n",
      "        20       23033.5282         438.4798           41.12s\n",
      "        30       17893.8183         304.6566           39.93s\n",
      "        40       15240.8629         166.3876           39.04s\n",
      "        50       13499.8553          63.9808           38.16s\n",
      "        60       12338.3082          76.8717           37.42s\n",
      "        70       11323.0530          88.4492           36.84s\n",
      "        80       10563.8517          33.4944           36.40s\n",
      "        90        9969.5042          21.8002           35.85s\n",
      "       100        9401.1661          48.3684           35.35s\n",
      "       200        6895.1283           3.8611           29.89s\n",
      "       300        5918.6277           1.7956           24.45s\n",
      "       400        5333.6763           1.0579           19.35s\n",
      "       500        4886.0763           1.8740           14.39s\n",
      "       600        4571.9165           0.4068            9.53s\n",
      "       700        4245.1173           3.0686            4.75s\n",
      "       800        4046.2229           0.4413            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       55250.1539        5610.7900           47.09s\n",
      "         2       51380.0581        3799.5764           44.92s\n",
      "         3       48059.1381        3214.6040           44.32s\n",
      "         4       45352.9270        2698.6621           44.40s\n",
      "         5       43409.2398        1897.3598           44.17s\n",
      "         6       40211.4235        3213.3367           43.93s\n",
      "         7       37534.5787        2679.8141           43.69s\n",
      "         8       35362.1312        2044.2994           43.35s\n",
      "         9       34051.1033        1296.7067           43.49s\n",
      "        10       33113.5329         949.7175           42.80s\n",
      "        20       22568.7509         670.5598           41.52s\n",
      "        30       17563.0183         425.9818           40.12s\n",
      "        40       14772.5711          87.0293           39.20s\n",
      "        50       13136.0147         171.2441           38.52s\n",
      "        60       12070.3991         112.7808           38.00s\n",
      "        70       11325.5574          68.4436           37.54s\n",
      "        80       10344.9094          58.9458           37.20s\n",
      "        90        9876.1555          58.7401           36.70s\n",
      "       100        9397.7912          16.6131           36.12s\n",
      "       200        6819.6062           4.9575           30.07s\n",
      "       300        5841.2816           4.4218           24.60s\n",
      "       400        5243.1192           4.2980           19.40s\n",
      "       500        4820.9879           1.1759           14.37s\n",
      "       600        4512.0831           2.4283            9.48s\n",
      "       700        4253.0488           1.0134            4.71s\n",
      "       800        4033.5208           0.4110            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       56898.9538        4811.2853            1.07m\n",
      "         2       52579.7978        4177.6958           58.80s\n",
      "         3       48956.5061        3652.7408           58.26s\n",
      "         4       45713.3127        3277.8229           57.47s\n",
      "         5       43089.1918        2495.3697           56.64s\n",
      "         6       40220.1475        2916.5228           56.11s\n",
      "         7       37147.0698        3056.6029           55.55s\n",
      "         8       35210.9951        1878.6870           55.15s\n",
      "         9       33320.2971        1979.2397           54.65s\n",
      "        10       32005.2316        1325.4491           54.44s\n",
      "        20       22092.4667         516.2213           52.94s\n",
      "        30       17661.7413         299.3572           51.00s\n",
      "        40       15225.0538         169.0077           49.89s\n",
      "        50       13599.5974         107.2854           49.24s\n",
      "        60       12585.8656          65.1530           48.20s\n",
      "        70       11560.6997          49.7636           47.50s\n",
      "        80       10664.0659          80.9995           46.82s\n",
      "        90       10011.7512          54.0674           46.15s\n",
      "       100        9528.4779          31.5926           45.43s\n",
      "       200        6995.7466          23.1818           38.33s\n",
      "       300        5963.9255           3.0426           31.56s\n",
      "       400        5433.2663           1.8624           24.93s\n",
      "       500        5024.9055           3.6160           18.57s\n",
      "       600        4684.6141           1.7124           12.28s\n",
      "       700        4434.3063           1.7806            6.10s\n",
      "       800        4179.2486           0.7945            0.00s\n",
      "gbm9\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59952.1417        3456.0558           54.76s\n",
      "         2       57646.5295        2223.3627           53.24s\n",
      "         3       55766.2675        2002.4394           51.52s\n",
      "         4       53602.6073        2411.1297           50.34s\n",
      "         5       51945.9494        1399.3604           49.12s\n",
      "         6       49914.8301        1999.4169           48.11s\n",
      "         7       48029.4817        1915.9305           47.77s\n",
      "         8       46717.7899        1425.9760           47.85s\n",
      "         9       44742.7413        2065.0756           47.84s\n",
      "        10       43411.0756        1079.2198           47.61s\n",
      "        20       33401.8012         501.2191           46.43s\n",
      "        30       27803.8415         284.9092           45.63s\n",
      "        40       24098.0094         176.9647           44.80s\n",
      "        50       20947.8022          76.7189           43.88s\n",
      "        60       19248.9329         108.4975           43.17s\n",
      "        70       17841.4922          66.7117           42.58s\n",
      "        80       16536.3940         125.7066           42.14s\n",
      "        90       15820.5057          47.5830           41.79s\n",
      "       100       14816.6418         208.9521           41.46s\n",
      "       200       10623.8509          12.7646           37.53s\n",
      "       300        9035.9253           6.2282           33.36s\n",
      "       400        8086.4983           0.8944           29.47s\n",
      "       500        7452.9369           7.7930           25.64s\n",
      "       600        6990.2192           2.2897           21.90s\n",
      "       700        6735.1360           1.3935           18.14s\n",
      "       800        6469.4495           0.0319           14.45s\n",
      "       900        6175.2213           5.3084           10.81s\n",
      "      1000        5994.5550           0.0415            7.19s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58381.3136        3388.6950           53.94s\n",
      "         2       56301.0901        2092.4860           50.18s\n",
      "         3       54479.8986        1835.9616           49.34s\n",
      "         4       52293.9357        2391.9407           48.85s\n",
      "         5       50793.6176        1340.5539           48.32s\n",
      "         6       48794.2733        1944.1297           48.03s\n",
      "         7       47155.8573        1750.8290           47.84s\n",
      "         8       45957.0446        1347.8696           47.54s\n",
      "         9       43909.7074        1987.4267           47.35s\n",
      "        10       42591.4707        1097.6868           47.27s\n",
      "        20       32695.9167         472.9927           46.06s\n",
      "        30       27216.9329         388.9376           45.36s\n",
      "        40       23075.9909         141.2203           44.69s\n",
      "        50       20034.2347          89.3973           43.67s\n",
      "        60       18493.5870          98.3291           43.01s\n",
      "        70       17106.1901         126.1601           42.34s\n",
      "        80       16130.5131         132.8413           41.86s\n",
      "        90       15431.3276          38.9195           41.49s\n",
      "       100       14491.8220         219.7306           41.18s\n",
      "       200       10438.4496          16.0921           37.31s\n",
      "       300        8853.2036          14.5589           33.24s\n",
      "       400        7847.9435           5.2018           29.40s\n",
      "       500        7294.8988          10.5296           25.54s\n",
      "       600        6877.0850           0.0876           21.76s\n",
      "       700        6607.8759           1.6697           18.30s\n",
      "       800        6324.0333           0.6976           15.05s\n",
      "       900        6083.7623           0.0592           11.41s\n",
      "      1000        5912.4927           0.3764            7.54s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57602.0872        3293.3262           52.72s\n",
      "         2       55678.5458        1995.0603           49.57s\n",
      "         3       53876.4484        1782.8409           48.91s\n",
      "         4       51738.3229        2313.1286           48.41s\n",
      "         5       50165.4304        1596.7765           48.26s\n",
      "         6       48171.5818        1855.5226           48.32s\n",
      "         7       46554.8345        1670.1299           48.78s\n",
      "         8       45167.5077        1518.4672           48.17s\n",
      "         9       43049.7943        1998.5833           48.01s\n",
      "        10       42014.5200        1009.2249           47.95s\n",
      "        20       32234.0021         460.2100           47.51s\n",
      "        30       26670.1936         398.3252           46.42s\n",
      "        40       23720.2310         174.4566           45.44s\n",
      "        50       20743.3324         145.7846           44.33s\n",
      "        60       19276.3159         108.6848           43.72s\n",
      "        70       17790.6515          61.6790           42.97s\n",
      "        80       16475.7298         151.5683           42.48s\n",
      "        90       15743.8041          40.5263           42.10s\n",
      "       100       14930.7713          68.5400           41.75s\n",
      "       200       10561.6567          10.4368           37.50s\n",
      "       300        8723.6728           9.8894           33.41s\n",
      "       400        7776.3502           2.9498           29.45s\n",
      "       500        7153.6336           1.5490           26.28s\n",
      "       600        6705.8830          -0.2054           22.52s\n",
      "       700        6426.0540           3.7421           18.97s\n",
      "       800        6159.0908           0.1309           15.36s\n",
      "       900        5894.4938           4.4907           11.55s\n",
      "      1000        5741.6522           0.4666            7.72s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58076.2510        3286.1101           58.15s\n",
      "         2       55993.3628        2001.9906           53.19s\n",
      "         3       54072.5627        1821.2943           53.34s\n",
      "         4       51820.1623        2347.0911           53.16s\n",
      "         5       50152.0215        1623.0902           53.36s\n",
      "         6       48170.9260        1883.5094           54.08s\n",
      "         7       46615.9585        1706.5044           54.64s\n",
      "         8       45184.8632        1546.3914           54.14s\n",
      "         9       42913.2525        2013.8524           53.91s\n",
      "        10       42040.5677        1017.4906           53.56s\n",
      "        20       32177.9318         472.9664           51.74s\n",
      "        30       26494.2518         385.7302           49.78s\n",
      "        40       22731.6621         130.6401           50.11s\n",
      "        50       19710.7741         116.6310           49.84s\n",
      "        60       18185.0956         124.2826           49.02s\n",
      "        70       16988.5045         127.1327           49.16s\n",
      "        80       15739.3216         156.6738           49.44s\n",
      "        90       14994.8837          46.2016           48.46s\n",
      "       100       14252.3638          87.1013           47.87s\n",
      "       200        9945.8268          14.5430           45.10s\n",
      "       300        8418.7838           9.2073           40.04s\n",
      "       400        7500.1003           1.7317           35.44s\n",
      "       500        6960.3589           4.4464           30.46s\n",
      "       600        6589.9279           0.0610           25.37s\n",
      "       700        6275.7591           2.7023           20.68s\n",
      "       800        6064.1784           0.0951           16.34s\n",
      "       900        5854.5909           6.0185           12.14s\n",
      "      1000        5705.8442           0.3728            8.04s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58472.8833        2372.5359           58.98s\n",
      "         2       56135.5797        2303.2199           54.51s\n",
      "         3       54118.5039        1937.2126           52.88s\n",
      "         4       52366.1104        1785.3433           53.67s\n",
      "         5       51017.0569        1296.9753           53.13s\n",
      "         6       48407.1237        2668.0073           52.85s\n",
      "         7       47078.4862        1371.4020           52.43s\n",
      "         8       45146.6809        1745.9300           52.09s\n",
      "         9       43997.1944        1137.4058           51.60s\n",
      "        10       43066.2450         997.5174           51.12s\n",
      "        20       33247.7502         733.0016           49.63s\n",
      "        30       26924.8916         602.0266           48.18s\n",
      "        40       23576.6039         202.9531           46.94s\n",
      "        50       20751.4978         138.2119           46.19s\n",
      "        60       18681.0323         358.4622           45.27s\n",
      "        70       17322.7911          75.5155           44.39s\n",
      "        80       16155.6885          72.6468           44.82s\n",
      "        90       15631.6224          37.0926           45.01s\n",
      "       100       14589.5296          63.3512           44.85s\n",
      "       200       10281.7504          19.2918           39.52s\n",
      "       300        8494.9278           6.9720           35.01s\n",
      "       400        7509.4794           8.2471           30.73s\n",
      "       500        6953.3275           2.7244           26.84s\n",
      "       600        6551.2397           3.2605           23.14s\n",
      "       700        6238.8922           0.8679           19.14s\n",
      "       800        5955.6310           1.6394           15.22s\n",
      "       900        5768.1138           0.0789           11.34s\n",
      "      1000        5585.4189           0.6328            7.60s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59085.9830        2642.9978            1.24m\n",
      "         2       56665.6601        2234.9656            1.14m\n",
      "         3       54312.4111        2414.1881            1.11m\n",
      "         4       52230.1275        2066.7512            1.09m\n",
      "         5       50619.5347        1572.6736            1.08m\n",
      "         6       48925.3212        1694.8392            1.07m\n",
      "         7       47038.7926        1921.8720            1.06m\n",
      "         8       45586.3630        1399.0576            1.06m\n",
      "         9       43768.8297        1915.7022            1.05m\n",
      "        10       42166.6958        1642.6997            1.04m\n",
      "        20       30995.7361         937.6667            1.01m\n",
      "        30       25129.0960         301.8151           59.11s\n",
      "        40       21637.9503         161.9251           58.07s\n",
      "        50       19528.7664         164.4590           57.24s\n",
      "        60       17785.3394          59.6953           56.31s\n",
      "        70       16579.0938          61.4167           55.76s\n",
      "        80       15557.1756         150.1284           55.20s\n",
      "        90       14753.0678          47.5495           55.26s\n",
      "       100       13997.0236         149.6773           55.24s\n",
      "       200       10167.3837          45.9696           49.96s\n",
      "       300        8648.4071          11.0251           45.19s\n",
      "       400        7771.6444          23.7479           40.44s\n",
      "       500        7289.7599           1.4050           35.58s\n",
      "       600        6909.1187           1.4218           30.69s\n",
      "       700        6530.6531           0.7824           25.64s\n",
      "       800        6251.8841           0.0552           20.42s\n",
      "       900        6040.5653          -0.0483           15.27s\n",
      "      1000        5850.5915           5.1529           10.39s\n",
      "gbm10\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59953.3878        3473.3773            1.33m\n",
      "         2       57127.3365        2762.1524            1.29m\n",
      "         3       54823.3908        2426.3823            1.28m\n",
      "         4       52459.4158        2565.4520            1.27m\n",
      "         5       50061.3539        2144.2098            1.26m\n",
      "         6       46963.2784        3019.9389            1.25m\n",
      "         7       45275.7905        1753.7616            1.25m\n",
      "         8       43438.4886        1949.8963            1.24m\n",
      "         9       42090.2827        1445.4884            1.23m\n",
      "        10       40436.3736        1395.9133            1.23m\n",
      "        20       28748.7199         608.6917            1.20m\n",
      "        30       22936.2809         291.8655            1.17m\n",
      "        40       19374.5535         189.4770            1.15m\n",
      "        50       17330.6992         102.6218            1.11m\n",
      "        60       15999.7613          79.2918            1.13m\n",
      "        70       14568.5108         170.7876            1.10m\n",
      "        80       13469.5542         115.8780            1.09m\n",
      "        90       12724.0465          49.2101            1.08m\n",
      "       100       12008.8915          53.9318            1.07m\n",
      "       200        8442.6815           6.2705           56.78s\n",
      "       300        7039.8188          15.9911           50.72s\n",
      "       400        6281.4244           1.2621           43.73s\n",
      "       500        5777.4347           2.5361           37.13s\n",
      "       600        5390.2553           0.4641           31.74s\n",
      "       700        5141.6763           2.7896           26.28s\n",
      "       800        4889.4799           0.2641           20.76s\n",
      "       900        4662.9410           0.6614           15.49s\n",
      "      1000        4474.9505           0.1456           10.36s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58430.6916        3337.6711            1.61m\n",
      "         2       55799.6924        2648.0247            1.53m\n",
      "         3       53446.9183        2330.9360            1.56m\n",
      "         4       51129.6529        2489.9333            1.57m\n",
      "         5       48903.9814        2041.8659            1.54m\n",
      "         6       45915.4735        2874.2811            1.51m\n",
      "         7       44408.2938        1614.5522            1.53m\n",
      "         8       42544.4616        1947.0677            1.55m\n",
      "         9       41105.1577        1441.0873            1.54m\n",
      "        10       39621.1002        1306.4302            1.51m\n",
      "        20       28572.6574         583.0591            1.44m\n",
      "        30       22681.9210         213.2702            1.40m\n",
      "        40       19170.3449         200.7312            1.38m\n",
      "        50       16942.9276          92.8281            1.33m\n",
      "        60       15380.4571          87.4180            1.33m\n",
      "        70       14031.0838         163.8466            1.32m\n",
      "        80       13068.9510         129.2254            1.31m\n",
      "        90       12407.1568          21.6679            1.26m\n",
      "       100       11794.0097          37.9302            1.24m\n",
      "       200        8126.2717           8.9522            1.07m\n",
      "       300        6916.6765          10.9941           57.29s\n",
      "       400        6172.7903           6.2190           50.31s\n",
      "       500        5708.5472           7.2905           42.45s\n",
      "       600        5316.7874           1.2494           34.89s\n",
      "       700        5078.1697           1.4278           28.24s\n",
      "       800        4822.7037          -0.1246           22.12s\n",
      "       900        4600.3436           0.1464           16.29s\n",
      "      1000        4434.7948          -0.3737           10.97s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57679.7199        3221.7522            1.38m\n",
      "         2       55211.9884        2545.4456            1.34m\n",
      "         3       52914.2776        2190.2288            1.29m\n",
      "         4       50646.1357        2457.3637            1.28m\n",
      "         5       48565.8328        2076.9175            1.26m\n",
      "         6       45535.2087        2853.0379            1.26m\n",
      "         7       43936.2477        1644.2703            1.25m\n",
      "         8       41908.2734        2117.9211            1.25m\n",
      "         9       39496.7015        2356.1557            1.23m\n",
      "        10       38269.7587        1216.1010            1.25m\n",
      "        20       27592.6082         587.1820            1.21m\n",
      "        30       21959.8089         266.1427            1.19m\n",
      "        40       18881.4186         256.1054            1.17m\n",
      "        50       16842.7544         147.6329            1.15m\n",
      "        60       15136.5244          85.1066            1.13m\n",
      "        70       13796.4340         178.1371            1.12m\n",
      "        80       13004.5669          99.0509            1.10m\n",
      "        90       12280.0337          33.2228            1.09m\n",
      "       100       11534.1780          48.0126            1.08m\n",
      "       200        8067.0286           9.3655           58.81s\n",
      "       300        6705.7856           6.1943           52.35s\n",
      "       400        6005.3230           2.6361           46.12s\n",
      "       500        5545.8658           0.7337           39.93s\n",
      "       600        5189.9335           0.7906           34.00s\n",
      "       700        4930.0618           2.5534           28.25s\n",
      "       800        4693.2104           0.4833           22.46s\n",
      "       900        4473.8137           6.1262           16.77s\n",
      "      1000        4307.7989          -0.1078           11.14s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58140.8553        3208.1875            1.35m\n",
      "         2       55564.6922        2484.0754            1.25m\n",
      "         3       53213.3124        2221.9069            1.23m\n",
      "         4       50790.4351        2493.5831            1.25m\n",
      "         5       48781.1001        1967.1801            1.24m\n",
      "         6       45872.2553        2742.9765            1.25m\n",
      "         7       44379.7988        1656.1108            1.25m\n",
      "         8       42284.2738        2162.7626            1.24m\n",
      "         9       39705.7653        2355.5391            1.23m\n",
      "        10       38583.5040        1253.1241            1.25m\n",
      "        20       27432.2749         678.0617            1.21m\n",
      "        30       21592.5096         254.4684            1.19m\n",
      "        40       18553.4375         190.1048            1.18m\n",
      "        50       16384.8006          76.5289            1.15m\n",
      "        60       14840.2736          96.1407            1.14m\n",
      "        70       13636.7756         115.1113            1.12m\n",
      "        80       12618.0341          59.3090            1.11m\n",
      "        90       11884.1926          33.5452            1.10m\n",
      "       100       11173.6253          61.1950            1.09m\n",
      "       200        7888.7004           5.4627            1.02m\n",
      "       300        6571.9302           6.6239           53.90s\n",
      "       400        5937.5349           2.1531           47.08s\n",
      "       500        5458.7398           4.1360           39.86s\n",
      "       600        5090.1976           0.2685           33.69s\n",
      "       700        4793.1655           0.7164           28.16s\n",
      "       800        4591.1806           0.5094           22.53s\n",
      "       900        4405.4407           2.7854           16.84s\n",
      "      1000        4264.1743           0.0607           11.15s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       57693.2208        3139.7483            1.35m\n",
      "         2       54938.5535        2738.4474            1.28m\n",
      "         3       52371.3511        2409.3109            1.27m\n",
      "         4       50140.5368        2274.7911            1.26m\n",
      "         5       48513.3743        1561.7301            1.25m\n",
      "         6       45959.7294        2583.9778            1.26m\n",
      "         7       44111.0775        1905.6269            1.24m\n",
      "         8       42076.7790        1797.7801            1.25m\n",
      "         9       40870.7774        1229.1827            1.25m\n",
      "        10       39460.8956        1412.9140            1.25m\n",
      "        20       29204.8790         785.9073            1.22m\n",
      "        30       22760.1505         535.8260            1.18m\n",
      "        40       19161.3627         282.4819            1.16m\n",
      "        50       16498.1145         259.8393            1.14m\n",
      "        60       15151.2205         127.8478            1.13m\n",
      "        70       14139.0403          60.7118            1.12m\n",
      "        80       12833.5998          96.1135            1.11m\n",
      "        90       12190.1352         136.7766            1.10m\n",
      "       100       11516.4220          30.7750            1.09m\n",
      "       200        7869.8114          10.8695           59.05s\n",
      "       300        6641.1204           4.8765           53.27s\n",
      "       400        5913.9806           1.6890           46.75s\n",
      "       500        5434.4466           7.3854           40.57s\n",
      "       600        5073.2746           0.9595           34.62s\n",
      "       700        4811.3378           1.5038           28.73s\n",
      "       800        4586.1449           0.8728           22.87s\n",
      "       900        4403.4196           0.1529           16.99s\n",
      "      1000        4236.8883           2.6446           11.25s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       58785.0958        2930.4290            2.05m\n",
      "         2       55852.2651        2749.5736            2.20m\n",
      "         3       53142.3088        2787.5472            2.25m\n",
      "         4       50074.0627        3092.4588            2.17m\n",
      "         5       47835.6135        2180.4843            2.18m\n",
      "         6       45476.1752        2381.8554            2.17m\n",
      "         7       43367.7636        2115.8664            2.17m\n",
      "         8       41777.9806        1546.3316            2.23m\n",
      "         9       39980.7446        1870.2950            2.23m\n",
      "        10       38375.1734        1611.5166            2.22m\n",
      "        20       27641.7839         867.0387            2.11m\n",
      "        30       21934.3551         311.2635            1.91m\n",
      "        40       18732.5616         194.8371            1.80m\n",
      "        50       16737.3141         197.9579            1.75m\n",
      "        60       15193.7857          69.7406            1.69m\n",
      "        70       14033.6571          56.9658            1.67m\n",
      "        80       13275.9368         148.5137            1.63m\n",
      "        90       12434.6642          47.3721            1.59m\n",
      "       100       11760.0738          83.8631            1.56m\n",
      "       200        8156.8765          37.8470            1.36m\n",
      "       300        6748.8888           5.5418            1.20m\n",
      "       400        6043.7206           4.8352            1.05m\n",
      "       500        5603.7461           3.6710           54.57s\n",
      "       600        5262.5212           1.5073           46.44s\n",
      "       700        5005.2001           4.0926           38.45s\n",
      "       800        4755.2650           0.4018           30.61s\n",
      "       900        4545.2678          -0.0673           22.83s\n",
      "      1000        4383.0197           0.5012           15.19s\n",
      "rfr3\n",
      "rfr5\n",
      "etr2\n"
     ]
    }
   ],
   "source": [
    "for model,modelName in zip(models,modelNames):\n",
    "    print(modelName)\n",
    "    rnd = randint(0,6)\n",
    "    stage0_final_train[modelName] = cross_val_predict(model,train_dataset[rnd],labels[rnd],cv=5)\n",
    "    model.fit(train_dataset[rnd],labels[rnd])\n",
    "    stage0_final_test[modelName] = model.predict(test_dataset[rnd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stage0_final_train.to_csv(\"stage0_train_data.csv\")\n",
    "stage0_final_test.to_csv(\"stage0_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbm1</th>\n",
       "      <th>gbm2</th>\n",
       "      <th>gbm3</th>\n",
       "      <th>gbm4</th>\n",
       "      <th>gbm5</th>\n",
       "      <th>gbm6</th>\n",
       "      <th>gbm7</th>\n",
       "      <th>gbm8</th>\n",
       "      <th>gbm9</th>\n",
       "      <th>gbm10</th>\n",
       "      <th>rfr3</th>\n",
       "      <th>rfr5</th>\n",
       "      <th>etr2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1417.199720</td>\n",
       "      <td>1392.156690</td>\n",
       "      <td>1398.896509</td>\n",
       "      <td>1392.579523</td>\n",
       "      <td>1428.321133</td>\n",
       "      <td>1393.254771</td>\n",
       "      <td>1429.603526</td>\n",
       "      <td>1429.444886</td>\n",
       "      <td>1415.002550</td>\n",
       "      <td>1397.983830</td>\n",
       "      <td>1209.584803</td>\n",
       "      <td>1210.637860</td>\n",
       "      <td>1170.342951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1293.343223</td>\n",
       "      <td>1377.903433</td>\n",
       "      <td>1330.968018</td>\n",
       "      <td>1290.240414</td>\n",
       "      <td>1263.214223</td>\n",
       "      <td>1342.207154</td>\n",
       "      <td>1236.231778</td>\n",
       "      <td>1383.708627</td>\n",
       "      <td>1353.423951</td>\n",
       "      <td>1362.103674</td>\n",
       "      <td>1240.997244</td>\n",
       "      <td>1243.033515</td>\n",
       "      <td>1211.548358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1377.667083</td>\n",
       "      <td>1348.741872</td>\n",
       "      <td>1352.448754</td>\n",
       "      <td>1351.806009</td>\n",
       "      <td>1372.983687</td>\n",
       "      <td>1366.117514</td>\n",
       "      <td>1345.874295</td>\n",
       "      <td>1325.368641</td>\n",
       "      <td>1393.511641</td>\n",
       "      <td>1335.130239</td>\n",
       "      <td>1245.805321</td>\n",
       "      <td>1226.637910</td>\n",
       "      <td>1254.292396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1316.859882</td>\n",
       "      <td>1274.255273</td>\n",
       "      <td>1269.797217</td>\n",
       "      <td>1258.137301</td>\n",
       "      <td>1269.669649</td>\n",
       "      <td>1273.395719</td>\n",
       "      <td>1233.365746</td>\n",
       "      <td>1188.221537</td>\n",
       "      <td>1289.937532</td>\n",
       "      <td>1312.209231</td>\n",
       "      <td>1319.112987</td>\n",
       "      <td>1294.551933</td>\n",
       "      <td>1260.193332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1418.342634</td>\n",
       "      <td>1304.211679</td>\n",
       "      <td>1362.333806</td>\n",
       "      <td>1317.798596</td>\n",
       "      <td>1385.117611</td>\n",
       "      <td>1406.381076</td>\n",
       "      <td>1331.092621</td>\n",
       "      <td>1277.814377</td>\n",
       "      <td>1350.180668</td>\n",
       "      <td>1388.598531</td>\n",
       "      <td>1353.236858</td>\n",
       "      <td>1332.734878</td>\n",
       "      <td>1277.920273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gbm1         gbm2         gbm3         gbm4         gbm5  \\\n",
       "0  1417.199720  1392.156690  1398.896509  1392.579523  1428.321133   \n",
       "1  1293.343223  1377.903433  1330.968018  1290.240414  1263.214223   \n",
       "2  1377.667083  1348.741872  1352.448754  1351.806009  1372.983687   \n",
       "3  1316.859882  1274.255273  1269.797217  1258.137301  1269.669649   \n",
       "4  1418.342634  1304.211679  1362.333806  1317.798596  1385.117611   \n",
       "\n",
       "          gbm6         gbm7         gbm8         gbm9        gbm10  \\\n",
       "0  1393.254771  1429.603526  1429.444886  1415.002550  1397.983830   \n",
       "1  1342.207154  1236.231778  1383.708627  1353.423951  1362.103674   \n",
       "2  1366.117514  1345.874295  1325.368641  1393.511641  1335.130239   \n",
       "3  1273.395719  1233.365746  1188.221537  1289.937532  1312.209231   \n",
       "4  1406.381076  1331.092621  1277.814377  1350.180668  1388.598531   \n",
       "\n",
       "          rfr3         rfr5         etr2  \n",
       "0  1209.584803  1210.637860  1170.342951  \n",
       "1  1240.997244  1243.033515  1211.548358  \n",
       "2  1245.805321  1226.637910  1254.292396  \n",
       "3  1319.112987  1294.551933  1260.193332  \n",
       "4  1353.236858  1332.734878  1277.920273  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage0_final_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       59556.2582        2186.5738           18.79s\n",
      "         2       57277.9744        2144.4481           17.39s\n",
      "         3       55325.1883        2039.0402           17.56s\n",
      "         4       53292.1932        1977.1175           17.16s\n",
      "         5       51435.0777        1880.9847           16.69s\n",
      "         6       49648.4775        1810.5167           16.85s\n",
      "         7       47935.0069        1735.6009           16.85s\n",
      "         8       46214.7869        1668.5637           16.52s\n",
      "         9       44697.6660        1591.4291           16.48s\n",
      "        10       43258.3881        1527.5784           16.33s\n",
      "        20       30745.1427        1017.4269           16.09s\n",
      "        30       22307.2686         693.4508           15.27s\n",
      "        40       16775.2319         466.8125           14.03s\n",
      "        50       13018.2916         311.8996           12.91s\n",
      "        60       10470.2042         208.9733           11.88s\n",
      "        70        8713.7387         141.7438           10.91s\n",
      "        80        7547.0767          99.1819           10.01s\n",
      "        90        6749.3344          64.7412            9.10s\n",
      "       100        6215.9370          44.2986            8.37s\n",
      "       200        4860.9756           2.1989            0.00s\n"
     ]
    }
   ],
   "source": [
    "params_stage1 = params_gbm = {'n_estimators': 200, 'max_depth': 5,'learning_rate': 0.02, 'loss': 'ls'}\n",
    "gbm_stage1 = GradientBoostingRegressor(**params_stage1,verbose=1,subsample=0.8,random_state=10,max_features=\"sqrt\",min_samples_split=200)\n",
    "\n",
    "gbm_stage1.fit(stage0_final_train,y1)\n",
    "ensemble_out1 = predict(gbm_stage1,\"approach4\",\"stacking_gbm\",stage0_final_test,IDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f912db9e9e8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEjCAYAAAA2Uaa4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nISIiOiQxREREhySGiIjokMQQEREd/huomLwPBl6mGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f912c5474a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "feat_imp = pd.Series(gbm_stage1.feature_importances_, stage0_final_train.columns).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "s1_train = stage0_final_train.drop([\"gbm1\",\"gbm2\",\"gbm7\",\"etr2\"],1)\n",
    "s1_test  = stage0_final_test.drop([\"gbm1\",\"gbm2\",\"gbm7\",\"etr2\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=500,max_depth=4,learning_rate=0.01)\n",
    "xgb_model.fit(s1_train,y1)\n",
    "ensemble_out2 = predict(xgb_model,\"approach4\",\"xgb_stage1\",s1_train,IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()\n",
    "out_df['Footfall'] = (ensemble_out1 + ensemble_out2)/2\n",
    "out_df['ID'] = IDS\n",
    "write_csv(\"results/approach4\",\"stage1_xgb_gbm_combined\",out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Final model public LB ~ 122 LS and private LB ~ 96**\n",
    "\n",
    "**Final rank on private leader board :- 34**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
